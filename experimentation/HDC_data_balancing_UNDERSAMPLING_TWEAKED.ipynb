{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDC model training notebook \n",
    "\n",
    "Steps:\n",
    "- load raw data \n",
    "- generate configs (hyper parameter)\n",
    "- do cross validation to find the best configs (hyper parameters)\n",
    "- train the model with the best hyperparameters in entire data from cross validation step \n",
    "- evaluate the model with test data (not included in cross validation train/val set)\n",
    "- save the model and result\n",
    "\n",
    "Note:\n",
    "in this notebook, the final performance of the model is evaluated with test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='HDC_balanced_UNDERSAMPLING_TWEAKED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1732869081399
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "import builtins\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Use local Executorch compatible copy of TorchHD\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"../../../torchhd\"))\n",
    "sys.path.insert(0, os.path.abspath(\"../../../torchhd/torchhd\"))\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "from torchhd import models\n",
    "print(torchhd.__file__) #Check\n",
    "print(embeddings.__file__) #Check\n",
    "print(models.__file__) #Check\n",
    "from typing import Union, Literal\n",
    "import json \n",
    "import pickle\n",
    "# import torchmetrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "from glob import glob\n",
    "import polars as pl \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Remove torchhd if already loaded\n",
    "if \"torchhd\" in sys.modules:\n",
    "    del sys.modules[\"torchhd\"]\n",
    "\n",
    "# Point to the actual package folder (the one with __init__.py)\n",
    "sys.path.insert(0, os.path.abspath(\"/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd\"))\n",
    "\n",
    "# Now import\n",
    "import torchhd\n",
    "from torchhd import embeddings, models\n",
    "\n",
    "# Sanity check\n",
    "print(torchhd.__file__)\n",
    "assert hasattr(models.Centroid, \"add_adjust\"), \"Custom torchhd still not loaded correctly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(models.Centroid, \"add_adjust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_COLUMNS = ['user_id', 'ZTIME', 'ZVALUEX_acc', 'ZVALUEY_acc', \n",
    "               'ZVALUEZ_acc', 'ZVALUEX_gyro', 'ZVALUEY_gyro', 'ZVALUEZ_gyro', 'ZHEARTRATE', 'ZAVERAGEHEARTRATE', \n",
    "              'tac (ug/L)', 'tac_flg', 'session_id']\n",
    "\n",
    "TAC_THRESHOLD = 35\n",
    "TAC_LEVEL_0 = 0\n",
    "TAC_LEVEL_1 = 1\n",
    "NUM_TAC_LEVELS = 2\n",
    "\n",
    "ALL_USERS = [ 6,  9, 10, 11, 14, 15, 16, 24, 25, 26, 28, 31]\n",
    "\n",
    "TRAIN_USERS = [[9, 10, 14, 15, 24, 28, 31],\n",
    "[10, 11, 6, 31],\n",
    "[6, 9, 11, 14, 15, 24, 28]]\n",
    "\n",
    "\n",
    "VALID_USERS = [[11, 6],\n",
    "[9, 14, 15, 24, 28],\n",
    "[10, 31]]\n",
    "\n",
    "TEST_USERS = [16,25,26]\n",
    "\n",
    "# base config \n",
    "BASE_CONFIGS = {\n",
    "    \"device\": \"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    \"window_size\": [40*20],\n",
    "    \"ngrams\": [7],\n",
    "    \"hdc_dimension\": 5000,\n",
    "    \"batch_size\": [64],\n",
    "    \"learning_rate\": [2],\n",
    "    \"epochs\": 10,\n",
    "    \"patience\": 5, # early stopping\n",
    "    \"overlap_ratio\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDED TWEAKS\n",
    "def add_noise(seq, level=0.01):\n",
    "    return seq + np.random.normal(0, level, seq.shape)\n",
    "\n",
    "def drift_signal(seq, max_shift=0.1):\n",
    "    drift = np.random.uniform(-max_shift, max_shift, (1, seq.shape[1]))\n",
    "    return seq + drift\n",
    "def time_shift(seq, max_shift=5):\n",
    "    shift = np.random.randint(-max_shift, max_shift)\n",
    "    return np.roll(seq, shift, axis=0)\n",
    "def mixup(seq1, seq2, alpha=0.3):\n",
    "    return alpha * seq1 + (1 - alpha) * seq2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(preprocess_fld='../../Preprocessed_all'):\n",
    "    file_paths = sorted(glob(preprocess_fld + '/after_preprocess_group*.csv'))\n",
    "    df_final = [pl.read_csv(file_path, columns=RAW_COLUMNS) for file_path in file_paths]\n",
    "    columns = df_final[-1].columns\n",
    "    df_final = pl.concat([data_df[columns] for data_df in df_final])\n",
    "    df_final = df_final.filter(df_final['user_id'].is_in(ALL_USERS))\n",
    "\n",
    "    # Rebuild session_id\n",
    "    df_final = (\n",
    "        df_final.with_columns([\n",
    "            pl.concat_str([\n",
    "                pl.col('user_id').cast(pl.Utf8),\n",
    "                pl.lit('_'),\n",
    "                pl.col('session_id')\n",
    "            ]).alias('combined_key')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col('combined_key').rank(method='dense').cast(pl.Int32).alias('session_id')\n",
    "        ])\n",
    "        .drop('combined_key')\n",
    "    )\n",
    "\n",
    "    # # Fix: invert labels – 1 = sober → 0, 0 = drunk → 1\n",
    "    # df_final = df_final.with_columns(\n",
    "    #     pl.col('tac_flg').cast(float).map_elements(lambda x: 1.0 - x).alias('tac_flg')\n",
    "    # )\n",
    "\n",
    "    return df_final.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, features, labels, window_size=10):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]),\n",
    "            torch.FloatTensor([self.labels[idx]]),\n",
    "        )\n",
    "\n",
    "class HdcGenericEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_size: int, out_dimension: int, ngrams: int = 5, dtype = torch.float32, device : str = \"cpu\"):\n",
    "        super(HdcGenericEncoder, self).__init__()\n",
    "\n",
    "        #Embeddings for raw data\n",
    "        self.input_size = input_size\n",
    "        self.keys = embeddings.Random(input_size, out_dimension, dtype=dtype, device=device)\n",
    "        self.motion_embed = embeddings.Level(3000, out_dimension, dtype=dtype, \n",
    "                                      low=-3.0, high=3.0, device=device)\n",
    "        self.hr_embed = embeddings.Level(200, out_dimension, dtype=dtype, \n",
    "                                      low=50, high=200, device=device)\n",
    "        self.ngrams = ngrams\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def batch_generic(self, id, levels, ngram):\n",
    "        batch_size = levels.shape[0]\n",
    "        multiset_list = []\n",
    "        for b in range(batch_size):\n",
    "            level = levels[b]\n",
    "            b_levels = [\n",
    "                torchhd.ngrams(level[0][i : i + ngram], ngram)\n",
    "                for i in range(1, id.shape[0] - ngram + 1)\n",
    "            ]\n",
    "            if len(b_levels) > 0:\n",
    "                b_levels = torch.stack(b_levels)\n",
    "                multiset_list.append(torchhd.multiset(torchhd.bind(id[:-ngram], b_levels)).unsqueeze(0))\n",
    "            else:\n",
    "                multiset_list.append(torchhd.multiset(torchhd.bind(id, level)))\n",
    "        return torch.stack(multiset_list)\n",
    "\n",
    "    # Encode window\n",
    "    def forward(self, channels: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, window_size, num_channels = channels.shape\n",
    "        motion_signals = channels[:, :, : self.input_size - 1]\n",
    "        hr_signals = channels[:, :, self.input_size - 1].unsqueeze(-1)\n",
    "        \n",
    "        # Use generic encoder\n",
    "        enc_motion_channels = self.motion_embed(motion_signals)\n",
    "        enc_hr_channel = self.hr_embed(hr_signals)\n",
    "        enc_channels = torch.cat([enc_motion_channels, enc_hr_channel], dim = 2)\n",
    "        sample_hvs = self.batch_generic(\n",
    "            self.keys.weight, enc_channels, self.ngrams\n",
    "        )\n",
    "        sample_hv = torchhd.multiset(sample_hvs)\n",
    "\n",
    "        sample_hv = torchhd.hard_quantize(sample_hv)\n",
    "        \n",
    "        return sample_hv\n",
    "    \n",
    "    \n",
    "class HdcModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        out_dimension: int,\n",
    "        ngrams: int = 5,\n",
    "        dtype=torch.float32,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super(HdcModel, self).__init__()\n",
    "        \n",
    "        self.encoder = HdcGenericEncoder(input_size, out_dimension, ngrams=ngrams, dtype=dtype, device=device)\n",
    "        self.centroid = models.Centroid(\n",
    "                out_dimension,\n",
    "                NUM_TAC_LEVELS,\n",
    "                dtype=dtype,\n",
    "                device=device,\n",
    "            )\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def add(self, x : torch.Tensor, y : torch.Tensor, lr : float):\n",
    "        hv = self.encoder(x)\n",
    "        labels = y.to(dtype=torch.int64)\n",
    "        for i in range(len(hv)):\n",
    "            #This operations can't be done in batches\n",
    "            self.centroid.add_adjust(\n",
    "                    hv[i].unsqueeze(0), labels[i], lr=lr\n",
    "                )\n",
    "            \n",
    "    def adjust_reset(self):\n",
    "        self.centroid.adjust_reset()\n",
    "        \n",
    "    #Executorch safe (0.6.x)\n",
    "    def vector_norm(self, x, p=2, dim=None, keepdim=False):\n",
    "        return torch.pow(torch.sum(torch.abs(x) ** p, dim=dim, keepdim=keepdim), 1 / p)\n",
    "        \n",
    "    def normalized_inference(self, input: torch.Tensor, dot: bool = False):\n",
    "        normalized_weight = self.centroid.weight.detach().clone()\n",
    "        norms = self.vector_norm(normalized_weight, p=2, dim=1, keepdim=True)\n",
    "        norms.clamp_(min=1e-12)\n",
    "        normalized_weight.div_(norms)\n",
    "\n",
    "        if dot:\n",
    "            return torchhd.functional.dot_similarity(input, normalized_weight)\n",
    "        return torchhd.functional.cosine_similarity(input, normalized_weight)\n",
    "        \n",
    "    def binary_hdc_output(self, outputs):\n",
    "        probs = F.softmax(outputs, dim=1)  # Shape: (batch_size, 2)\n",
    "        return probs[:, 1]  # Extract only class 1 probability\n",
    "        \n",
    "    def forward(self, x : torch.Tensor):\n",
    "        hv = self.encoder(x)\n",
    "        output = self.normalized_inference(hv, True)\n",
    "\n",
    "        return self.binary_hdc_output(output)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def prepare_sequences_undersampled(df, window_size=10, overlap_ratio=0.1, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Generate sequences and apply undersampling to balance class distribution.\n",
    "    \"\"\"\n",
    "    session_user_map = pd.Series(df[\"user_id\"].values, index=df[\"session_id\"]).astype(int).to_dict()\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "    print(f\"Preparing sequences with undersampling...\")\n",
    "\n",
    "    features = df[feature_columns].values\n",
    "    labels = df[\"tac_flg\"].values\n",
    "    session_ids = df[\"session_id\"].values\n",
    "    unique_sessions = np.unique(session_ids)\n",
    "\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    sequence_user_ids = []\n",
    "\n",
    "    for session_id in tqdm(unique_sessions):\n",
    "        session_mask = session_ids == session_id\n",
    "        session_indices = np.where(session_mask)[0]\n",
    "\n",
    "        if len(session_indices) >= window_size:\n",
    "            for start_idx in range(0, len(session_indices) - window_size + 1, int(window_size * overlap_ratio)):\n",
    "                window_indices = session_indices[start_idx : start_idx + window_size]\n",
    "                if len(window_indices) < window_size:\n",
    "                    continue\n",
    "\n",
    "                sequence = features[window_indices]\n",
    "                label = int(stats.mode(labels[window_indices].astype(int), keepdims=False).mode)\n",
    "\n",
    "                sequences.append(sequence)\n",
    "                sequence_labels.append(label)\n",
    "                sequence_user_ids.append(session_user_map[session_id])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequence_labels = np.array(sequence_labels)\n",
    "    sequence_user_ids = np.array(sequence_user_ids)\n",
    "\n",
    "    # === Undersample the majority class (label == 1)\n",
    "    print(\"Balancing sequences via undersampling...\")\n",
    "\n",
    "    sober_mask = sequence_labels == 1\n",
    "    drunk_mask = sequence_labels == 0\n",
    "\n",
    "    sober_seqs = sequences[sober_mask]\n",
    "    sober_labels = sequence_labels[sober_mask]\n",
    "    sober_users = sequence_user_ids[sober_mask]\n",
    "\n",
    "    drunk_seqs = sequences[drunk_mask]\n",
    "    def augment_drunk(seqs, labels, users, n_aug=1):\n",
    "        new_seqs, new_labels, new_users = [], [], []\n",
    "        for i in range(len(seqs)):\n",
    "            for _ in range(n_aug):\n",
    "                aug_seq = add_noise(seqs[i], level=0.01)\n",
    "                new_seqs.append(aug_seq)\n",
    "                new_labels.append(labels[i])\n",
    "                new_users.append(users[i])\n",
    "        return (\n",
    "            np.concatenate([seqs, np.stack(new_seqs)]),\n",
    "            np.concatenate([labels, new_labels]),\n",
    "            np.concatenate([users, new_users]),\n",
    "        )\n",
    "\n",
    "    \n",
    "    drunk_labels = sequence_labels[drunk_mask]\n",
    "    drunk_users = sequence_user_ids[drunk_mask]\n",
    "    \n",
    "    drunk_seqs, drunk_labels, drunk_users = augment_drunk(drunk_seqs, drunk_labels, drunk_users, n_aug=1)\n",
    "    if len(drunk_seqs) == 0 or len(sober_seqs) == 0:\n",
    "        raise ValueError(\"Insufficient class samples for undersampling.\")\n",
    "\n",
    "    undersample_ratio = 1  # or test 1.2, 1.3...\n",
    "    n_samples = min(len(sober_seqs), int(len(drunk_seqs) * undersample_ratio))\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "    if len(sober_seqs) > n_samples:\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=(len(sober_seqs) - n_samples), random_state=42)\n",
    "        idxs_to_keep, _ = next(sss.split(sober_seqs, sober_users))\n",
    "        sober_seqs_resampled = sober_seqs[idxs_to_keep]\n",
    "        sober_labels_resampled = sober_labels[idxs_to_keep]\n",
    "        sober_users_resampled = sober_users[idxs_to_keep]\n",
    "    else:\n",
    "        # Not enough to subsample, just keep all\n",
    "        sober_seqs_resampled = sober_seqs\n",
    "        sober_labels_resampled = sober_labels\n",
    "        sober_users_resampled = sober_users\n",
    "\n",
    "\n",
    "\n",
    "    # Combine and shuffle\n",
    "    sequences_balanced = np.concatenate([sober_seqs_resampled, drunk_seqs])\n",
    "    labels_balanced = np.concatenate([sober_labels_resampled, drunk_labels])\n",
    "    users_balanced = np.concatenate([sober_users_resampled, drunk_users])\n",
    "\n",
    "    indices = np.arange(len(labels_balanced))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    sequences_balanced = sequences_balanced[indices]\n",
    "    labels_balanced = labels_balanced[indices]\n",
    "    users_balanced = users_balanced[indices]\n",
    "\n",
    "    print(f\"Undersampled sequence shape: {sequences_balanced.shape}\")\n",
    "\n",
    "    return sequences_balanced, labels_balanced, users_balanced\n",
    "\n",
    "def prepare_sequences_fast(df, window_size=10, overlap_ratio=0.1, feature_columns=None):\n",
    "        session_user_map = pd.Series(df[\"user_id\"].values, index=df[\"session_id\"]).astype(int).to_dict()\n",
    "        if feature_columns is None:\n",
    "            feature_columns = [\n",
    "                \"ZVALUEX_acc\",\n",
    "                \"ZVALUEY_acc\",\n",
    "                \"ZVALUEZ_acc\",\n",
    "                \"ZVALUEX_gyro\",\n",
    "                \"ZVALUEY_gyro\",\n",
    "                \"ZVALUEZ_gyro\",\n",
    "                \"ZHEARTRATE\",\n",
    "            ]\n",
    "\n",
    "        print(f\"Starting sequence preparation...\")\n",
    "\n",
    "        # 特徴量とラベルを事前にNumPy配列に変換\n",
    "        features = df[feature_columns].values\n",
    "        labels = df[\"tac_flg\"].values\n",
    "        session_ids = df[\"session_id\"].values\n",
    "\n",
    "        # セッションのユニークなIDと各セッションのインデックスを取得\n",
    "        unique_sessions = np.unique(session_ids)\n",
    "        print(f\"Processing {len(unique_sessions)} sessions...\")\n",
    "\n",
    "        sequences = []\n",
    "        sequence_labels = []\n",
    "        sequence_user_ids = []\n",
    "\n",
    "        for session_id in tqdm(unique_sessions):\n",
    "            session_mask = session_ids == session_id\n",
    "            session_indices = np.where(session_mask)[0]\n",
    "\n",
    "            if len(session_indices) >= window_size:\n",
    "                for start_idx in range(\n",
    "                    0, len(session_indices) - window_size + 1, np.ceil(window_size*overlap_ratio).astype(int)\n",
    "                ):\n",
    "                    window_indices = session_indices[start_idx : start_idx + window_size]\n",
    "                    if len(window_indices) < window_size:\n",
    "                        continue\n",
    "\n",
    "                    sequence = features[window_indices]\n",
    "                    # get the mode label in the current window\n",
    "                    label = stats.mode(labels[window_indices].astype(int))[0]\n",
    "\n",
    "                    sequences.append(sequence)\n",
    "                    sequence_labels.append(label)\n",
    "                    sequence_user_ids.append(session_user_map[session_id])\n",
    "\n",
    "        sequences = np.array(sequences)\n",
    "        sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "        print(f\"Created {len(sequences)} sequences\")\n",
    "        print(f\"Sequences shape: {sequences.shape}\")\n",
    "\n",
    "        return sequences, sequence_labels, sequence_user_ids\n",
    "\n",
    "\n",
    "def validate_model(model, valid_loader, criterion, device):\n",
    "    \"\"\"検証データでのモデル評価\"\"\"\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.squeeze(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(outputs.cpu().numpy())\n",
    "            val_labels.extend(batch_y.squeeze(-1).cpu().numpy())\n",
    "\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    val_prauc = average_precision_score(val_labels, val_preds)\n",
    "    val_rocauc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    return {\n",
    "        \"loss\": val_loss / len(valid_loader),\n",
    "        \"pr_auc\": val_prauc,\n",
    "        \"roc_auc\": val_rocauc,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model : HdcModel,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    criterion,\n",
    "    lr,\n",
    "    device,\n",
    "    epochs=100,\n",
    "    patience=5,\n",
    "):\n",
    "    best_val_prauc = 0\n",
    "    patience_counter = 0\n",
    "    best_train_epoch = 0\n",
    "    best_model_state = None\n",
    "    training_history = []\n",
    "\n",
    "    print(\n",
    "        \"Epoch | Train Loss |  Val Loss  |  Val PR-AUC  |  Val ROC-AUC  |  Epoch Time (s)\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            model.add(batch_X, batch_y, lr)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.squeeze(-1))\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        model.adjust_reset()\n",
    "\n",
    "        if valid_loader is None:\n",
    "            epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"time\": epoch_time}\n",
    "            training_history.append(epoch_results)\n",
    "            print(f\"{epoch+1:5d} | {train_loss:.6f} | ------ | ------ | {epoch_time:.2f}\")\n",
    "            continue\n",
    "    \n",
    "        val_metrics = validate_model(model, valid_loader, criterion, device)\n",
    "        epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_metrics[\"loss\"], \n",
    "                         \"val_pr_auc\": val_metrics[\"pr_auc\"], \"val_roc_auc\": val_metrics[\"roc_auc\"], \"time\": epoch_time}\n",
    "        training_history.append(epoch_results)\n",
    "\n",
    "        print(\n",
    "            f\"{epoch+1:5d} | {train_loss:.6f} | {val_metrics['loss']:.6f} | \"\n",
    "            f\"{val_metrics['pr_auc']:.4f} | {val_metrics['roc_auc']:.4f} | \"\n",
    "            f\"{epoch_time:.2f}\"\n",
    "        )\n",
    "        \n",
    "        if val_metrics[\"pr_auc\"] >= best_val_prauc:\n",
    "            best_val_prauc = val_metrics[\"pr_auc\"]\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "            best_train_epoch = epoch\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after epoch {epoch+1}\")\n",
    "            print(f\"Best validation PR-AUC: {best_val_prauc:.4f}\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None: \n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model, training_history, best_train_epoch\n",
    "\n",
    "\n",
    "def inference_dataset(model, data_loader, device, pred_threshold=None):\n",
    "    \"\"\"evaluation model after a fold training\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            labels.extend(batch_y.squeeze(-1).cpu().numpy())\n",
    "\n",
    "    pred_prob = np.array(predictions)\n",
    "    gt_labels = np.array(labels)\n",
    "    return pred_prob, gt_labels\n",
    "\n",
    "\n",
    "def performance_calculation(pred_prob, gt_label, threshold=None):\n",
    "    '''\n",
    "    Calculate the performance of the model\n",
    "    Args:\n",
    "    pred_prob: list, predicted probability\n",
    "    gt_label: list, ground truth label\n",
    "    threshold: float, threshold for binary classification (None if we are evaluating on train data)\n",
    "    '''\n",
    "    if threshold is None:\n",
    "        # Find the optimal threshold by maximizing F1 score\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)  # Test 99 threshold values\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5  # Default if no better threshold is found\n",
    "        \n",
    "        for t in thresholds:\n",
    "            temp_pred = (pred_prob >= t).astype(int)\n",
    "            temp_f1 = (f1_score(gt_label, temp_pred, pos_label=0) + f1_score(gt_label, temp_pred, pos_label=1)) / 2\n",
    "\n",
    "            \n",
    "            if temp_f1 > best_f1:\n",
    "                best_f1 = temp_f1\n",
    "                best_threshold = t\n",
    "        \n",
    "        threshold = best_threshold\n",
    "        \n",
    "    pred_label = (pred_prob >= threshold).astype(int)\n",
    "    roc_auc = roc_auc_score(gt_label, pred_prob)\n",
    "    pr_auc = average_precision_score(gt_label, pred_prob)\n",
    "    accuracy = accuracy_score(gt_label, pred_label)\n",
    "\n",
    "    # Since 0 = drunk and 1 = sober\n",
    "    drunk_acc = accuracy_score(gt_label[gt_label == 0], pred_label[gt_label == 0])\n",
    "    sober_acc = accuracy_score(gt_label[gt_label == 1], pred_label[gt_label == 1])\n",
    "\n",
    "    f1 = f1_score(gt_label, pred_label)\n",
    "    return roc_auc, pr_auc, accuracy, sober_acc, drunk_acc, f1, threshold\n",
    "\n",
    "\n",
    "def generate_configs(base_config):\n",
    "    \"\"\"\n",
    "    Generate multiple configurations from a base config.\n",
    "    For any list values in the base config, create a separate config for each list item.\n",
    "    \n",
    "    Args:\n",
    "        base_config (dict): Base configuration with potential list values\n",
    "        \n",
    "    Returns:\n",
    "        list: List of individual configurations\n",
    "    \"\"\"\n",
    "    # Find all keys with list values\n",
    "    list_keys = [key for key, value in base_config.items() if isinstance(value, list)]\n",
    "    \n",
    "    if not list_keys:\n",
    "        # If no list values found, return the original config\n",
    "        return [base_config]\n",
    "    \n",
    "    # Start with the first list key\n",
    "    key = list_keys[0]\n",
    "    values = base_config[key]\n",
    "    \n",
    "    # Generate configurations for each value of the first list key\n",
    "    configs = []\n",
    "    for value in values:\n",
    "        # Create a new config with this specific value\n",
    "        new_config = base_config.copy()\n",
    "        new_config[key] = value\n",
    "        \n",
    "        # Recursively handle any remaining list keys\n",
    "        remaining_configs = generate_configs(new_config)\n",
    "        configs.extend(remaining_configs)\n",
    "    \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_results(model, save_folder, train_preds, train_gt_labels, test_preds, test_gt_labels, metrics, config):\n",
    "    \"\"\"\n",
    "    Save model, predictions, ground truth, metrics, and model structure to the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        save_folder: Folder path to save results\n",
    "        train_preds: Training predictions\n",
    "        train_gt_labels: Training ground truth labels\n",
    "        test_preds: Test predictions\n",
    "        test_gt_labels: Test ground truth labels\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "        config: Model configuration dictionary\n",
    "    \"\"\"\n",
    "    # Create a timestamp for the save files\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(save_folder, f\"model_{timestamp}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save model architecture as text\n",
    "    model_structure_path = os.path.join(save_folder, f\"model_structure_{timestamp}.txt\")\n",
    "    with open(model_structure_path, 'w') as f:\n",
    "        f.write(str(model))\n",
    "    \n",
    "    # Save predictions and ground truth\n",
    "    predictions_data = {\n",
    "        'train_predictions': train_preds.tolist() if isinstance(train_preds, np.ndarray) else train_preds,\n",
    "        'train_ground_truth': train_gt_labels.tolist() if isinstance(train_gt_labels, np.ndarray) else train_gt_labels,\n",
    "        'test_predictions': test_preds.tolist() if isinstance(test_preds, np.ndarray) else test_preds,\n",
    "        'test_ground_truth': test_gt_labels.tolist() if isinstance(test_gt_labels, np.ndarray) else test_gt_labels\n",
    "    }\n",
    "    pred_path = os.path.join(save_folder, f\"predictions_{timestamp}.pkl\")\n",
    "    with open(pred_path, 'wb') as f:\n",
    "        pickle.dump(predictions_data, f)\n",
    "    \n",
    "    # Save all metrics\n",
    "    metrics_path = os.path.join(save_folder, f\"metrics_{timestamp}.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    # Save the configuration\n",
    "    config_path = os.path.join(save_folder, f\"config_{timestamp}.json\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    print(f\"Model, predictions, ground truth, and metrics saved in {save_folder}\")\n",
    "\n",
    "\n",
    "def train_and_eval_final_model(best_config, best_threshold, df):\n",
    "    print('\\nBEGIN TRAIN AND EVALUATION FINAL MODEL\\n')\n",
    "    feature_columns = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        \"ZHEARTRATE\",\n",
    "    ]\n",
    "\n",
    "    # Hyper parameter loading\n",
    "    device = best_config['device'] \n",
    "    window_size = best_config['window_size']\n",
    "    input_size = len(feature_columns)\n",
    "    batch_size = best_config['batch_size']\n",
    "    hdc_dimension = best_config['hdc_dimension']\n",
    "    ngrams = best_config['ngrams']\n",
    "    learning_rate = best_config['learning_rate']\n",
    "    epochs = best_config['epochs']\n",
    "    patience = best_config['patience']\n",
    "    runtime_log_fld = best_config['runtime_log_fld']\n",
    "    overlap_ratio = best_config['overlap_ratio']\n",
    "    \n",
    "    train_user = list(set(ALL_USERS)- set(TEST_USERS))\n",
    "    test_user = TEST_USERS\n",
    "        \n",
    "    train_data = df[df['user_id'].isin(train_user)]\n",
    "    test_data = df[df['user_id'].isin(test_user)]\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    scaler = StandardScaler()\n",
    "    train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "    test_data[columns_to_standardize] = scaler.transform(test_data[columns_to_standardize])\n",
    "\n",
    "    print(\"Preparing sequences...\")\n",
    "    X_train, y_train, train_user_ids = prepare_sequences_undersampled(train_data, window_size, overlap_ratio)\n",
    "    X_test, y_test, test_user_ids = prepare_sequences_fast(test_data, window_size, overlap_ratio)\n",
    "\n",
    "\n",
    "    print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "    print(f\"Users in test:{set(test_data['user_id'])}\")\n",
    "    print(f\"Number of windows for training:{len(X_train)}\")\n",
    "    print(f\"Number of windows for testing:{len(X_test)}\")\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = HdcModel(input_size, hdc_dimension, ngrams, device=device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 02. Train model (set patience to ensure that the model is trained for the best epoch)\n",
    "    model, training_history, _ = train_model(\n",
    "        model=model, train_loader=train_loader, valid_loader=None, \n",
    "        criterion=criterion, lr=learning_rate, device=device, epochs=epochs\n",
    "    )\n",
    "\n",
    "    # 03. Inference\n",
    "    train_preds, train_gt_labels = inference_dataset(model, train_loader, device)\n",
    "    test_preds, test_gt_labels = inference_dataset(model, test_loader, device)\n",
    "\n",
    "    # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "    train_roc_auc, train_pr_auc, train_accuracy, train_sober_acc, train_drunk_acc, train_f1, train_threshold = performance_calculation(train_preds, train_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Training ROC-AUC: {train_roc_auc:.4f}, PR-AUC: {train_pr_auc:.4f}, Accuracy: {train_accuracy:.4f}, Sober Accuracy: {train_sober_acc:.4f}, Drunk Accuracy: {train_drunk_acc:.4f}, F1: {train_f1:.4f}, Threshold: {train_threshold:.4f}\")\n",
    "    test_roc_auc, test_pr_auc, test_accuracy, test_sober_acc, test_drunk_acc, test_f1, test_threshold = performance_calculation(test_preds, test_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Test ROC-AUC: {test_roc_auc:.4f}, PR-AUC: {test_pr_auc:.4f}, Accuracy: {test_accuracy:.4f}, Sober Accuracy: {test_sober_acc:.4f}, Drunk Accuracy: {test_drunk_acc:.4f}, F1: {test_f1:.4f}, Threshold: {test_threshold:.4f}\")    \n",
    "\n",
    "    # 05. Save model, predictions, ground truth, metrics and model structure\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'roc_auc': train_roc_auc,\n",
    "            'pr_auc': train_pr_auc,\n",
    "            'accuracy': train_accuracy,\n",
    "            'sober_accuracy': train_sober_acc,\n",
    "            'drunk_accuracy': train_drunk_acc,\n",
    "            'f1': train_f1,\n",
    "            'threshold': train_threshold\n",
    "        },\n",
    "        'test': {\n",
    "            'roc_auc': test_roc_auc,\n",
    "            'pr_auc': test_pr_auc,\n",
    "            'accuracy': test_accuracy,\n",
    "            'sober_accuracy': test_sober_acc,\n",
    "            'drunk_accuracy': test_drunk_acc,\n",
    "            'f1': test_f1,\n",
    "            'threshold': test_threshold\n",
    "        },\n",
    "        'config': best_config\n",
    "    }\n",
    "    \n",
    "    # Call the function to save all results\n",
    "    save_model_and_results(\n",
    "        model=model,\n",
    "        save_folder=runtime_log_fld,\n",
    "        train_preds=train_preds,\n",
    "        train_gt_labels=train_gt_labels,\n",
    "        test_preds=test_preds,\n",
    "        test_gt_labels=test_gt_labels,\n",
    "        metrics=metrics,\n",
    "        config=best_config\n",
    "    )\n",
    "    \n",
    "    # refresh GPU\n",
    "    model.to(\"cpu\")\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    return train_accuracy, test_accuracy, metrics\n",
    "\n",
    "def train_cross_validation(df, all_configs):\n",
    "    print(\"=\"*50 + \"\\nBEGIN CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    best_config = None \n",
    "    best_pr_auc = 0\n",
    "    best_threshold = 0.5 \n",
    "    for config_idx, config in enumerate(all_configs):\n",
    "        print(f\"\\nCONFIG {config_idx}: {config}\\n\")\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "        # Hyper parameter loading\n",
    "        device = config['device'] \n",
    "        window_size = config['window_size']\n",
    "        input_size = len(feature_columns)\n",
    "        batch_size = config['batch_size']\n",
    "        hdc_dimension = config['hdc_dimension']\n",
    "        ngrams = config['ngrams']\n",
    "        learning_rate = config['learning_rate']\n",
    "        epochs = config['epochs']\n",
    "        overlap_ratio = config['overlap_ratio']\n",
    "        patience = config['patience']\n",
    "\n",
    "        # variables for temperary storing\n",
    "        val_all_preds = []\n",
    "        val_all_gt_labels = []\n",
    "        val_trained_epoch = []\n",
    "\n",
    "        for fold, (train_user, val_user) in enumerate(zip(TRAIN_USERS, VALID_USERS)):\n",
    "\n",
    "            # 01. Prepare data and define model\n",
    "            print(\"-\" * 100)\n",
    "            print('FOLD:', fold+1)\n",
    "            print('TRAIN:', train_user)\n",
    "            print('VAL:', val_user)\n",
    "            \n",
    "            train_data = df[df['user_id'].isin(train_user)].copy()\n",
    "            val_data = df[df['user_id'].isin(val_user)].copy()\n",
    "\n",
    "            # columns will be normalized\n",
    "            columns_to_standardize = [\n",
    "                \"ZVALUEX_acc\",\n",
    "                \"ZVALUEY_acc\",\n",
    "                \"ZVALUEZ_acc\",\n",
    "                \"ZVALUEX_gyro\",\n",
    "                \"ZVALUEY_gyro\",\n",
    "                \"ZVALUEZ_gyro\",\n",
    "                #'ZHEARTRATE'\n",
    "            ]\n",
    "\n",
    "            # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "            scaler = StandardScaler()\n",
    "            train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "            val_data[columns_to_standardize] = scaler.transform(val_data[columns_to_standardize])\n",
    "\n",
    "            print(\"Preparing sequences...\")\n",
    "            X_train, y_train, train_user_ids = prepare_sequences_undersampled(train_data, window_size, overlap_ratio)\n",
    "            X_val, y_val, val_user_ids = prepare_sequences_undersampled(val_data, window_size, overlap_ratio)\n",
    "\n",
    "            print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "            print(f\"Users in test:{set(val_data['user_id'])}\")\n",
    "            print(f\"Number of windows for training:{len(X_train)}\")\n",
    "            print(f\"Number of windows for testing:{len(X_val)}\")\n",
    "\n",
    "            train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "            val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            model = HdcModel(input_size, hdc_dimension, ngrams, device=device)\n",
    "\n",
    "            criterion = nn.BCELoss()\n",
    "            #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            # 02. Train model \n",
    "            model, training_history, train_best_epoch = train_model(\n",
    "                model, train_loader, val_loader, criterion, lr=learning_rate, device=device, \n",
    "                epochs=epochs, patience=patience\n",
    "            )\n",
    "\n",
    "            # 03. Inference\n",
    "            val_preds, val_gt_labels = inference_dataset(model, val_loader, device)\n",
    "            val_all_preds.append(val_preds)\n",
    "            val_all_gt_labels.append(val_gt_labels)\n",
    "            val_trained_epoch.append(train_best_epoch)\n",
    "\n",
    "            # refresh GPU\n",
    "            model.to(\"cpu\")\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "        # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "        val_all_preds = np.concatenate(val_all_preds)\n",
    "        val_all_gt_labels = np.concatenate(val_all_gt_labels)\n",
    "        val_roc_auc, val_pr_auc, val_accuracy, val_sober_acc, val_drunk_acc, val_f1, val_threshold = performance_calculation(val_preds, val_gt_labels)\n",
    "        print(f\"Validation ROC-AUC: {val_roc_auc:.4f}, PR-AUC: {val_pr_auc:.4f}, Accuracy: {val_accuracy:.4f}, Sober Accuracy: {val_sober_acc:.4f}, Drunk Accuracy: {val_drunk_acc:.4f}, F1: {val_f1:.4f}, Threshold: {val_threshold:.4f}\")\n",
    "        \n",
    "        # 05. set up best config\n",
    "        if val_pr_auc > best_pr_auc:\n",
    "            best_pr_auc = val_pr_auc\n",
    "            best_config = config\n",
    "            best_threshold = val_threshold\n",
    "            best_config_epoch = np.ceil(np.mean(val_trained_epoch)) + 1\n",
    "            print(f\"Updated best config: {best_config}, PR-AUC: {best_pr_auc:.4f}, Threshold: {best_threshold:.4f}, Epoch: {best_config_epoch:.2f}\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    best_config['epochs'] = int(best_config_epoch)\n",
    "    best_config['patience'] = int(best_config_epoch)\n",
    "    print(f'Final best config: {best_config}, Final best pr_auc: {best_pr_auc}, Final best threshold: {best_threshold}, Final best epoch: {best_config_epoch}')\n",
    "    print(\"=\"*50 + \"\\nEND CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    return best_config, best_pr_auc, best_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_file_path):\n",
    "    # Configure logging\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Remove existing handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Add file handler\n",
    "    file_handler = logging.FileHandler(log_file_path)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Create a custom print function\n",
    "    original_print = print\n",
    "    \n",
    "    def custom_print(*args, **kwargs):\n",
    "        # Call original print\n",
    "        # original_print(*args, **kwargs)\n",
    "        # Log the printed content\n",
    "        message = \" \".join(str(arg) for arg in args)\n",
    "        logger.info(f\"PRINT: {message}\")\n",
    "    \n",
    "    # Replace built-in print\n",
    "    import builtins\n",
    "    builtins.print = custom_print\n",
    "    \n",
    "    logger.info(f\"Logging initialized to {os.path.abspath(log_file_path)}\")\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime():\n",
    "    # 1.set up logging\n",
    "    runtime_log_fld = f\"results/{MODEL_NAME}/{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    if os.path.exists(runtime_log_fld) == False:\n",
    "        os.makedirs(runtime_log_fld)\n",
    "    logger = setup_logging(f\"{runtime_log_fld}/training.log\")\n",
    "    \n",
    "    # 2.set up configurations\n",
    "    base_configs = BASE_CONFIGS\n",
    "    base_configs['runtime_log_fld'] = runtime_log_fld   \n",
    "    all_configs = generate_configs(base_configs)\n",
    "    print(f\"Total configurations: {len(all_configs)}\")\n",
    "\n",
    "    # 3.Load the raw data\n",
    "    df = load_data()\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    # scaler = StandardScaler()\n",
    "    # df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "    # 4. Train and evaluate all configurations\n",
    "    # get the best config of current model \n",
    "    # get the best threshold of drunk or sober based on all fold validation data when using best config\n",
    "    best_config, best_pr_auc, best_threshold = train_cross_validation(df, all_configs)\n",
    "\n",
    "    # 5.Train and evaluate the final model with the best configuration\n",
    "    # train the final model on all data in cross validation and evaluate on test data\n",
    "    # calculate the performance and save the model, metrics and best config \n",
    "    train_and_eval_final_model(best_config, best_threshold, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:03<00:00,  9.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 20.22it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 13.89it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  7.92it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  8.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.13it/s]\n",
      "100%|██████████| 43/43 [00:04<00:00,  9.05it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 19.93it/s]\n"
     ]
    }
   ],
   "source": [
    "runtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHqCAYAAADs9fEjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWUdJREFUeJzt3Qd0VNXWwPFNCTH0EAgBpCm9CAgYwEKV3p4FFEUUBKR3EBXERhMBAUFABKSrFFERqVIeTRCkiChFipQgPSGEEOZb+/hmvkwKTnDgZu78f6y7MnPvmZkzw0qys88+56RxOBwOAQAA8CNpre4AAADA3UYABAAA/A4BEAAA8DsEQAAAwO8QAAEAAL9DAAQAAPwOARAAAPA7BEAAAMDvEAABAAC/QwAEJLB792556aWXpHDhwnLPPfdI5syZ5cEHH5SRI0fK+fPn7+hr79y5U6pXry7ZsmWTNGnSyNixY73+Gvq8Q4YMkbttxowZ5rX1+OGHHxJd10XpixQpYq7XqFHjtl5j4sSJ5nVSQvuSXJ8A2Fd6qzsApCZTp06Vzp07S/HixaVfv35SqlQpiY2Nle3bt8vHH38smzdvlsWLF9+x12/btq1ERUXJ/PnzJTg4WAoVKuT119D3cO+994pVsmTJItOmTUsU5Kxbt04OHTpkrt8uDYBy5swpL774oseP0eBWPxP9vwbgPwiAgP/RX4KdOnWSxx9/XJYsWSKBgYGua3quT58+snz58jvah71790r79u2lQYMGd+w1qlSpIlZq2bKlzJkzRz766CPJmjWr67wGRVWrVpXLly/flX5oYKuZH+2D1Z8JgLuPITDgf4YOHWp+IU6ZMsUt+HHKkCGDNG3a1HX/5s2bZlisRIkSpn1oaKi88MILcuLECbfHaaajTJky8uOPP8qjjz4qGTNmlPvuu0+GDx9uniP+8NCNGzdk0qRJrqEipcNVztvxOR/zxx9/uM6tWbPGvF5ISIgEBQVJgQIF5Mknn5SrV6/ecghMA69mzZqZrJMO+5UvX15mzpyZ5FDRvHnz5PXXX5e8efOa4KFOnTpy4MABjz/nZ5991nzV53G6dOmSLFy40GTAkvLWW29JeHi45MiRw7ymZm00YIq/l7Nmy/bt22cySc7Pz5lBc/Z91qxZJpDNly+f+T87ePBgoiGwv/76S/Lnzy/VqlUzQZLTL7/8IpkyZZLWrVt7/F4BpF4EQICIxMXFmeChYsWK5pefJzRbNGDAAJMdWrp0qbzzzjsmQ6S/OPWXaHynT5+W5557Tp5//nnTVjM8AwcOlNmzZ5vrjRo1Mhko9dRTT5nbzvue0kBIn0cDtU8//dT0RYMs/aV9/fr1ZB+nwYv2WYOHcePGyaJFi8xwkA4jaYCX0GuvvSZHjx6VTz75xASLv//+uzRp0sR8hp7QAEbfo/bRSYOhtGnTmuxQcu+tY8eO8vnnn5v+PfHEE9KtWzfzmTvp0KQGlhUqVHB9fgmHK/UzP3bsmBnO/Prrr03QmpAOoekQpAas+v+rNIB8+umnTUCpjwVgAw4AjtOnT2sqwfHMM8941H7//v2mfefOnd3Ob9261Zx/7bXXXOeqV69uzum1+EqVKuWoV6+e2zlt16VLF7dzb775pjmf0PTp0835I0eOmPtffvmlub9r165b9l3b6HM66XsODAx0HDt2zK1dgwYNHBkzZnRcvHjR3F+7dq15bMOGDd3aff755+b85s2bb/m6zv7++OOPrufau3evuVa5cmXHiy++aG6XLl3afGbJiYuLc8TGxjrefvttR0hIiOPmzZuua8k91vl6jz32WLLX9Gt8I0aMMOcXL17saNOmjSMoKMixe/fuW75HAL6DDBBwG9auXWu+Jiy2feihh6RkyZKyevVqt/NhYWHmWnwPPPCAyaR4iw5bafanQ4cOZvjq8OHDHj1OM1+1a9dOlPnS96aZj4SZqPjDgM73oVLyXnSm2/3332+yQHv27DHZluSGv5x91KE2nR2XLl06CQgIkMGDB8u5c+ckIiLC49fV4UBPaRG8ZtR0yE4/z/Hjx0vZsmU9fjyA1I0ACPjfsIfW5hw5csSj9vqLV+XJkyfRNa2NcV530pqchLQGJTo6WrxFA4pVq1aZYZ0uXbqY+3p8+OGHt3yc9jW59+G8fqv34qyXSsl70ZobXWpAhwB1SKlYsWKmPiop27Ztk7p167pm6f33v/81AZPWIaX0dZN6n7fqowaB165dMwEstT+AvRAAASImq6BZkB07diQqYk6KMwg4depUomsnT540AZW3aFGyiomJcTufsM5IaRChtS1aVLxlyxYzq6pnz56mpuVW7yW596G8+V7i0+BC34MGQBoMJUf7rhmfb775Rlq0aGHqlSpVqnRbr5lUMXly9DPRQFIzaxoE9u3b97ZeE0DqRAAExCuQ1RIZnYaeVNGwzgjS4ELVqlXLfHUWMTtpZmL//v0mmPIW50wmXaAxPmdfkgvodNaUTjVXP/30U7Jtta86xOQMeJw+++wzkxW7U1PEdSaWDjNpAXWbNm1uGbSkT5/evCcnzfrojK47lVXTgm4d+tLX/u6772TYsGFmCEwLsAHYA+sAAf+j2RKdgq4LIepsMJ3lVbp0aRP46ArNOuNJp7PrL2xdKFFrbfSXos5e0lldOlNp0KBBppamV69eXutXw4YNzfTvdu3aydtvv22CAZ0Cf/z4cbd2mknRQEbrVnS2kg7dOGdaaf1Mct58802TXalZs6apq9HX0nV6vv32WzMLTOtu7hSdpfZP9P2MHj1aWrVqZT5zzcaMGjUqyaUKtEZHM0YLFiwwM8I0e3Y7dTv6mWzYsEFWrFhhhr906rxOr9f/A51lpquEA/BtBEBAPJr90WLlMWPGyIgRI8z0dR1+0RoV/QXctWtXV1sNlrTGRtej0UyLBgr169c32YKkan5ul04b1yntOpSl0+izZ88uL7/8sgm69KuTDtXoL2z95a391i08NGDTaffOGpqkaDC3adMmM71dh3w0g6KF3NOnT0/Risp3imbbNJDT/w8NPjVzpP9PWuukAUnC9YJ06EqvX7lyRQoWLOi2TpInVq5caf4PNZiNn8nToFODH52qv3HjRlNwDsB3pdGpYFZ3AgAA4G6iBggAAPgdAiAAAOB3CIAAAIDfIQACAAB+hwAIAAD4HQIgAADgdwiAAACA37HlQohzdvzzXk4A/lnlfDms7gJgC8XCMt6V1wmq8P+LtXpD9M4JYldkgAAAgN+xZQYIAAC/lIa8hqf4pAAAgN8hAwQAgF2kSWN1D3wGARAAAHbBEJjH+KQAAIDfIQMEAIBdMATmMQIgAADsgiEwj/FJAQAAv0MGCAAAu2AIzGMEQAAA2AVDYB7jkwIAAH6HDBAAAHbBEJjHyAABAAC/QwYIAAC7oAbIYwRAAADYBUNgHiNUBAAAfocMEAAAdsEQmMcIgAAAsAuGwDxGqAgAAP61YcOGSeXKlSVLliwSGhoqzZs3lwMHDri1cTgcMmTIEMmbN68EBQVJjRo1ZN++fW5tYmJipFu3bpIzZ07JlCmTNG3aVE6cOOHW5sKFC9K6dWvJli2bOfT2xYsXU9RfAiAAAOw0BObNIwXWrVsnXbp0kS1btsjKlSvlxo0bUrduXYmKinK1GTlypIwePVomTJggP/74o4SFhcnjjz8uV65ccbXp2bOnLF68WObPny8bN26UyMhIady4scTFxbnatGrVSnbt2iXLly83h97WICgl0jg0HLOZOTvcI0UAt6dyvhxWdwGwhWJhGe/K6wQ9NsSrzxe9/vaf7+zZsyYTpIHRY489ZrI/mvnRAGfAgAGubE/u3LllxIgR0rFjR7l06ZLkypVLZs2aJS1btjRtTp48Kfnz55dly5ZJvXr1ZP/+/VKqVCkTaIWHh5s2ertq1ary66+/SvHixT3qHxkgAADswssZoJiYGLl8+bLboec8ocGMypHj7z+kjhw5IqdPnzZZIafAwECpXr26bNq0ydzfsWOHxMbGurXRoKlMmTKuNps3bzbDXs7gR1WpUsWcc7bxBAEQAAB2kTaNV49hw4a56mych577J5rt6d27tzzyyCMmeFEa/CjN+MSn953X9GuGDBkkODj4lm00s5SQnnO28QSzwAAAQJIGDhxoApn4NGvzT7p27Sq7d+82NTwJpUkwU02DpYTnEkrYJqn2njxPfARAAADYhZfXAQoMDPQo4IlPZ3AtXbpU1q9fL/fee6/rvBY8K83S5MmTx3U+IiLClRXSNtevXzezvOJngbRNtWrVXG3OnDmTZM1RwuzSrTAEBgCAXWgGxJtHCmgGRjM/ixYtkjVr1kjhwoXdrut9DV50hpiTBjtaJO0MbipWrCgBAQFubU6dOiV79+51tdFiZ60v2rZtm6vN1q1bzTlnG0+QAQIAAP+aToGfO3eufPXVV2YtIGc9jtYN6Zo/OjylM8CGDh0qRYsWNYfezpgxo5nW7mzbrl076dOnj4SEhJgC6r59+0rZsmWlTp06pk3JkiWlfv360r59e5k8ebI516FDBzNV3tMZYIoACAAAu7BwK4xJkyaZr7q4YXzTp0+XF1980dzu37+/REdHS+fOnc0wl87kWrFihQmYnMaMGSPp06eXFi1amLa1a9eWGTNmSLp06Vxt5syZI927d3fNFtPFEnVtoZRgHSAAyWIdIMDH1gF6fIRXny965d/r9dgRNUAAAMDvMAQGAIBdsBu8x/ikAACA3yEDBACAXaRw6ro/IwACAMAuGALzGJ8UAADwO2SAAACwC4bAPEYABACAXTAE5jE+KQAA4HfIAAEAYBcMgXmMDBAAAPA7ZIAAALALaoA8RgAEAIBdEAB5jE8KAAD4HTJAAADYBUXQHiMAAgDALhgC8xifFAAA8DtkgAAAsAuGwDxGBggAAPgdMkAAANgFNUAeIwACAMAuGALzGKEiAADwO2SAAACwiTRkgDxGAAQAgE0QAHmOITAAAOB3yAABAGAXJIA8RgAEAIBNMATmQ0Ngs2fPTvZav3797mpfAACAf7A8AOratat88803ic736tXrlsERAABInAHy5mFnlgdA8+fPl+eff17Wr1/vOtetWzf5/PPPZe3atZb2DQAA2JPlNUD169eXjz/+WJo3by4rVqyQTz/9VL766isT/BQrVszq7gEA4DPsnrWxVQCknnnmGblw4YI88sgjkitXLlm3bp0UKVLE6m4BAOBTCIBSeQDUu3fvJM+HhoZKhQoVZOLEia5zo0ePvos9AwAA/sCSAGjnzp1Jnr///vvl8uXLrutEsgAApAC/NlN3EbTW93hyrFmzxoruAQDgk6yeBbZ+/Xpp0qSJ5M2b1zx+yZIlbtcjIyPN7O97771XgoKCpGTJkjJp0iS3NjExMWYyVM6cOSVTpkzStGlTOXHihFsbLZtp3bq1ZMuWzRx6++LFi741CwwAANhDVFSUlCtXTiZMmJDkdV3iZvny5WaZm/3795v7Guzo5Cennj17yuLFi80s8Y0bN5qgqXHjxhIXF+dq06pVK9m1a5d5Lj30tgZBPlUErR/W8OHDZfXq1RIRESE3b950u3748GHL+gYAgC+xunSkQYMG5kjO5s2bpU2bNlKjRg1zv0OHDjJ58mTZvn27NGvWTC5duiTTpk2TWbNmSZ06dUwbDZby588vq1atknr16pnASYOeLVu2SHh4uGkzdepUqVq1qhw4cECKFy/uGwHQyy+/bGZ9aeSWJ08ey//zAADAnaGzvZcuXSpt27Y1w2Q//PCD/Pbbb/Lhhx+a6zt27JDY2FipW7eu6zHarkyZMrJp0yYTAGkQpcNezuBHValSxZzTNj4TAH333Xfy7bffysMPP2x1VwAA8GneTiLExMSYI77AwEBz3I5x48ZJ+/btTQ1Q+vTpJW3atPLJJ5+YwEidPn1aMmTIIMHBwW6Py507t7nmbKOzxhPSc842PlEDpG8yR44cVncDAACf5+0i6GHDhrkKjZ2HnrtdGgDp0JVmgTTb88EHH0jnzp3N8NatOBwOt+AuqUAvYZtUnwF65513ZPDgwTJz5kzJmDGj1d0BAAD/M3DgwERr991u9ic6Olpee+01U+DcqFEjc+6BBx4wBcyjRo0yNT9hYWFy/fp1M8srfhZIa4SrVatmbmubM2fOJHr+s2fPmkyRzwRAGv0dOnTIdLpQoUISEBDgdv2nn36yrG8AAPgUL5fRBv6L4a6EtLZHDx32ii9dunSuCVAVK1Y0ccDKlSulRYsW5typU6dk7969MnLkSHNfi521WHrbtm3y0EMPmXNbt24155xBkk8EQLoHGAAA+PesnkgUGRkpBw8edN0/cuSIyfBoqUuBAgWkevXq0q9fP7MGUMGCBc0kqM8++8y164MOsbVr10769OkjISEh5nF9+/aVsmXLumaF6dpBuo+o1hLpDDLnbDKdKu9pAbRK49BBM5uZs8N9wSQAt6dyPurzAG8oFnZ3Sjxyvjjfq8/314xnUtReZ3XVrFkz0Xmd+j5jxgxTpKzDarr5+fnz500QpMGLrgfkDN6uXbtmgqS5c+eaYbPatWubLbJ0KryTPrZ79+6mlkjpYom69lD27Nk97isBEIBkEQABvhUA5XppgVef7+z0lmJXlg+B6VjgrVJ28Vd+BAAAsEUApNXg8WmBlG6GqrPC3nrrLcv6BQCAr7G6BsiXWB4A6dLXCT311FNSunRpWbBggSmGAgAAHiD+8Z2FEJOjS1z/08JIAAAAPpkBSopWfY8fP94slQ0AADzDEJgPBUC60mP8/zCdlHblyhWzKrTuAAsAADxDAORDAdDYsWMTzQrLlSuXGQJLuBkaAACAzwdAN27ckD/++EPatm3rtsARAABIOTJAPlIEnT59erMBGmv9AACQ+naDtzPLZ4HpEte6dDYAAIDf1AA1aNDA7AuiO73qLrCZMmVyu677ewAAAA/YO2ljrwCoU6dO5qtzJ9j4NP3G8BgAALBdAHTz5k2ruwAAgC3YvW7HVgEQAADwDgIgHwmANPszY8YMWbRokZkOr/9xhQsXNnuBtW7dmv9IAABgr1lguuKzFji//PLL8ueff0rZsmXNBqhHjx6VF198Uf7zn/9Y1TUAAHwS0+B9IAOkmZ/169fL6tWrpWbNmm7X1qxZI82bN5fPPvtMXnjhBau6CACAb7F3zGKPDNC8efPktddeSxT8qFq1asmrr74qc+bMsaRvAADA3iwLgHbv3i3169e/5fpAP//8813tEwAAvowhMB8IgM6fPy+5c+dO9rpeu3Dhwl3tEwAA8A+W1QDpAoe6F1hy0qVLZzZLhe+Iib4qP3wxXX7dvlGiLl2UsEJFpN4LXSTf/SXM9a8+HiE/r1/h9ph8RUpKu7cnuO7fiL0uK+dMlr2b1pjbhUtXkIYv9ZCsIbnu+vsBrDB3+scyb8Zkt3PZc4TIrMWrzO0L58/JjMkfyq4fN0tkZKSUKfegdOzRX/LeW9DVPvb6dfl04mhZt+Z7uR5zTco9+JB06vWa5AxN/o9O2IPdsza2CIB0FpjO9goMDEzyekxMzF3vE/6dr6d+IGePH5HmnQZKluAQ2b1xlcwe2l86vT9Nsub4O4C5v1xladaxv+sx6RIEwd9/NlF+27lZnuz2hgRlySorZ38s80a9Lu3fmyRp06a76+8JsEKBwvfLux987LqfNl1a18/N917vZf54fP29sZIxUyZZ8vlseaP3KzJx5iK5JyjItJs6/n3Ztnm99B88TLJkzW6CobcHdpcxU+aaPy5hXwRAPjAE1qZNGwkNDZVs2bIleeg1ZoD5jtjrMbJ/23qp3aqDFCz5gOQIyyc1nmoj2UPDZPuqr13t0qcPkMzZc7iOoMxZXdeuXY2UnT98J3Wfe0XuK1tR8hQqKv/pMlAijh2Rw3t+suidAXefBinBITldR7bsOcz5kyeOyYFf9kin3q9LsZKl5d4ChaRTr4FyLTpa1q3+zrSJirwiK5ctkXade0v5SlXk/mIlpPcb78rRwwfl5x1bLX5nQOphWQZo+vTpVr007oCbcXHiuHlT0gdkcDuv948f2Ou6/8f+n2XUK0/KPRkzScGS5aRWi7aSKVuwuXbqyO9yM+6G3Fe2kqt9luCcEpq/kJz4fZ8UKVf5Lr4jwDoa6LR54nHz/VO8VBl5oX03Cct7rxnaUhkyZHALlvQPi1/27JJ6jZ+Qg7/tN+UDFSpXdbUJyRlqskr79/4sDz5UzZL3hLuDDJAPZIBgL4FBGeXeoqVkw+LZcuXCX3LzZpzs3rhS/jz0q0RePGfaFCn3kPyny2vywuuj5PHnXpGThw/IZ+/1NbU+KvLieUmXPkCCMmdxe24NkPQa4A+KlSwjvV57R956f6J06zfI1Pz06/KiXL50Ue4tWEhCw/LIzCnjJfLKZYmNjZUv5nwqF87/JRfO/WUef+HcOUkfECCZs/x/dlVlDw4xzwWbS+Plw8Z8fi8wrRVKWC+kwzEBGZKuLcKd07zzQFk6+X0Z06WlpEmb1gxhla1WS0798bu5Xrrq/6/5FJq/sOS9r7h82L2V/L5zq5R86NFkn1frHvirBv6iUpVH4t0rKiVKl5P2rZrImuVfS/OWrWXg26Nk3Mi35NnG1SVtunRSvmK4VAx/+J+f2Hwf3cmeA77F5wOgYcOGyVtvveV27j/te8mTHXtb1id/lSN3Xnlx8Bi5fi3azAjTQugvx70j2XPlSbK9Xs+eM7ecP33C3NeaoLgbsRIdecUtC3T18kXJX6z0XXsfQGqihc2FChcxw2KqSPFSMm7aAlPrc+NGrKkP6vNKa3NeBYeEyI3YWJMhip8FunjxvJQoU86y94G7gz8W/WgIbODAgXLp0iW3o+lLXazull/LcE+QCW40kDm0+0cpXjHpmoOrVy7JpfMRkjl7iLmfp3BRSZsuvRzeu8PV5sqFcxJx/A+5tygBEPyT1v0cP3bEFEPHlylzFhP8nDxxVA4e+EXCH6lhzhcpVtLMEtv54xZX2/PnzsqxI4ekJAEQYJ8MkE6jTziVPiDDZcv6488O/vyj5tklJE9+OX/mT1k1d4q5Xb56fZMV+mHhTClZ+VETHF08e1rWLJgmGbNkkxKV/07535Mxs1So0cBMfdfZYZoF0jWBQgsUlvvKPmj12wPuimkTR8tD1R6TXLnzyKUL52XBZ5/I1agoqV2/ibm+ce1KyZY9WHLlDpM/Dv9uprxr8PPg/4qeNTB6vGFzM/U9a7ZskjlLNvl00hgpeF8RKVcx3OJ3hzuNDFAqD4CWLl3qcVvdMR6+ISY6StbM/0Qun//LBC8a7NRs2das9aNF0TqdffeGlXItKlKyBOeQQqXKy5PdB5kCaqd6rTubuoaF4942f/nqQojN+r7LGkDwG+fOnpFRbw80Rc9ZswdL8VJlZdSkmRIalteVzZn20Qdy8cI5kxWqVa+xtHyhg9tzvNy1r5kdNmLIAFMjqQsh9hz2IWsA+QHiH8+lcWiF6V2WNm1ajyNZXTE6pebs+LumBMC/Uznf3+vPAPh3ioX9/x96d1KRvn+vB+UtB0c1ELuyJAN08+ZNK14WAABbYwjMj2qAAADA34h/fCwAioqKknXr1smxY8fk+v9WOnXq3r27Zf0CAAD2ZPk0+J07d0qRIkXk2Wefla5du8q7774rPXv2lNdee03Gjh1rdfcAAPCpITBvHim1fv16adKkieTNm9c8fsmSJYna7N+/30xw0n0/s2TJIlWqVDEJECct3O/WrZvkzJlTMmXKZNqeOOFe23vhwgVp3bq1a/9QvX3x4kXfCoB69eplPqzz589LUFCQbNmyRY4ePSoVK1aUUaNGWd09AAB8hsYs3jxuZ0SnXLlyMmHChCSvHzp0SB555BEpUaKE/PDDD/Lzzz/LoEGD5J577nG10STI4sWLZf78+bJx40aJjIyUxo0bu02KatWqlezatUuWL19uDr2tQVCqnwUWX/bs2WXr1q1SvHhxc3vz5s1SsmRJc053jP/1119T/JzMAgO8g1lggG/NAivx6vdefb5fh9e77cdqBkgDmebNm7vOPfPMMxIQECCzZs1K8jG6mHGuXLnM9ZYtW5pzJ0+elPz588uyZcukXr16JoNUqlQpkzAJD/97bSu9XbVqVRMzaDzhExkg/SCcabbcuXO70mCa0oqfEgMAALeWNm0arx7engH+7bffSrFixUwgExoaagKY+MNkO3bsMJv81q1b13VOh9PKlCkjmzZtMvc1UaIxgjP4UTqMpuecbXwiAKpQoYJs377d3K5Zs6YMHjxY5syZY1JgZcuWtbp7AAD4rZiYGLl8+bLbkXADck9FRESY4azhw4dL/fr1ZcWKFfKf//xHnnjiCTMRSp0+fVoyZMggwcHBbo/VBIlec7bR4CkhPeds4xMB0NChQyVPnr83y3znnXckJCREOnXqZD6oKVOmWN09AAD8tgZo2LBhrkJj56Hn/s0agM2aNTP1v+XLl5dXX33V1Pd8/PHHt3ysVuvEL8pOqkA7YZtUPw2+UqVKrts67qdjfAAAwPqFEAcOHCi9e/d2O5dw/01P6awu3ahX63fi07pfLXZWYWFhZjkcneUVPwukSZFq1aq52pw5cybR8589e9ZkinwmAwQAAFKnwMBAyZo1q9txuwGQDm1VrlxZDhw44Hb+t99+k4IFC5rbOgNca4NXrlzpun7q1CnZu3evKwDSYmctlt62bZurjU6c0nPONj6RASpcuPAtI9bDhw/f1f4AAOCrrF4JOjIyUg4ePOi6f+TIETNFPUeOHFKgQAHp16+fmd312GOPmbpfncL+9ddfmynxSofY2rVrJ3369DElMfq4vn37mprgOnXquDJGWkPUvn17mTx5sjnXoUMHM5Tm6QywVBEAabFzfFr9rYsj6oeiHxQAAPCNvcC2b99uAhsn5/CZLmszY8YMU/Ss9T5aR6Q7PWjAsnDhQrM2kNOYMWPMUFmLFi0kOjpaateubR6bLl06VxudLKWPd84W08USk1t7KNWuA5Scjz76yHyQ06dPT/FjWQcI8A7WAQJ8ax2gBwav8urz7X7776yLHaXaGqAGDRqYqBAAAPjGVhi+JNUGQF9++aUZ+wMAAPC29KlhIcT4UaaOyOlCRjqdbeLEiZb2DQAAX2LzpI29AiBdECl+AJQ2bVqzHlCNGjXMZmkAAMAzdh+2slUANGTIEKu7AAAA/IzlNUA6rU1XeEzo3LlzblPeAADA3d0Kw84szwAlNwtfN1vTVSMBAIBnGALzgQBo3Lhxrv+sTz75RDJnzuy6FhcXJ+vXr6cGCAAA2CsA0pUenRkgXRUy/nCXZn4KFSr0j7vDAgCA/0cCyAcCIN0fROmS2YsWLXLb9RUAAMDWNUBr1661ugsAANgCNUA+NAvsqaeekuHDhyc6//7778vTTz9tSZ8AAPBFzALzoQBo3bp10qhRo0Tndat7LYQGAACw3RBYZGRkktPdAwIC5PLly5b0CQAAX8QQmA9lgMqUKSMLFixIdH7+/PlSqlQpS/oEAIAvYgjMhzJAgwYNkieffFIOHToktWrVMudWr14t8+bNky+++MLq7gEAABuyPABq2rSpLFmyRIYOHSpffvmlBAUFyQMPPCCrVq2S6tWrW909AAB8BkNgPhQAKS2CTqoQeteuXVK+fHlL+gQAgK8h/vGhGqCELl26JBMnTpQHH3xQKlasaHV3AACADaWaAGjNmjXy3HPPSZ48eWT8+PHSsGFD2b59u9XdAgDAp4bAvHnYmaVDYCdOnJAZM2bIp59+KlFRUdKiRQuJjY2VhQsXMgMMAADYLwOkGR4Ncn755ReT8Tl58qT5CgAAbg/T4H0gA7RixQrp3r27dOrUSYoWLWpVNwAAsA27D1vZIgO0YcMGuXLlilSqVEnCw8NlwoQJcvbsWau6AwAA/IhlAVDVqlVl6tSpcurUKenYsaNZ+Tlfvnxy8+ZNWblypQmOAACA5yiC9qFZYBkzZpS2bdvKxo0bZc+ePdKnTx+zO3xoaKhZJBEAAHiGGiAfCoDiK168uIwcOdLMDtOtMAAAAGy7EnRC6dKlk+bNm5sDAAB4xu7DVrbNAAEAAPhtBggAAKQcCSDPEQABAGATDIF5jiEwAADgd8gAAQBgEySAPEcABACATaQlAvIYQ2AAAMDvEAABAGATVq8EvX79emnSpInkzZvXFGQvWbIk2ba6DZa2GTt2rNv5mJgY6datm+TMmVMyZcpkdoXQBZLju3DhgrRu3VqyZctmDr198eLFFPWVAAgAAJuwei+wqKgoKVeunNng/FY0MNq6dasJlBLq2bOnLF682OwRqttkRUZGSuPGjSUuLs7VplWrVrJr1y5Zvny5OfS2BkEpQQ0QAADwigYNGpjjVv7880/p2rWrfP/999KoUSO3a5cuXZJp06bJrFmzpE6dOubc7NmzJX/+/LJq1SqpV6+e7N+/3wQ9W7ZskfDwcNNGN1fXTdYPHDhgttXyBBkgAABsIm0a7x4xMTFy+fJlt0PP3a6bN2+aTE2/fv2kdOnSia7v2LFDYmNjpW7duq5zmiUqU6aMbNq0ydzfvHmzGfZyBj+qSpUq5pyzjUef1W2/CwAAYGvDhg1z1dk4Dz13u0aMGCHp06eX7t27J3n99OnTkiFDBgkODnY7nzt3bnPN2SY0NDTRY/Wcs40nGAIDAMAmvL0S9MCBA6V3795u5wIDA2/ruTS78+GHH8pPP/2U4n46HA63xyT1+IRt/gkZIAAAbMLbs8ACAwMla9asbsftBkAbNmyQiIgIKVCggMkC6XH06FHp06ePFCpUyLQJCwuT69evm1le8enjNAvkbHPmzJlEz3/27FlXG08QAAEAgDtOa392795tZmw5D63v0XogLYhWFStWlICAAFm5cqXrcadOnZK9e/dKtWrVzH0tdtZi6W3btrna6IwyPeds4wmGwAAAsIk0Yu1K0JGRkXLw4EHX/SNHjphAJ0eOHCbzExIS4tZegx3N6DhnbmmNUbt27UxWSNvq4/r27Stly5Z1zQorWbKk1K9fX9q3by+TJ0825zp06GCmyns6A0wRAAEAYBM6c8tK27dvl5o1a7ruO+uH2rRpIzNmzPDoOcaMGWOGx1q0aCHR0dFSu3Zt89h06dK52syZM8cUUjtni+liif+09lBCaRxaNWQzc3a4rxgJ4PZUzpfD6i4AtlAsLONdeZ2mU3706vMt7VBZ7IoMEAAANuHtWWB2RhE0AADwO2SAAACwCRJAniMAAgDAJtISAXmMITAAAOB3yAABAGATJIA8RwAEAIBNMAvMcwyBAQAAv0MGCAAAmyAB5DkyQAAAwO+QAQIAwCaYBu85AiAAAGyC8MdzDIEBAAC/QwYIAACbYBq85wiAAACwibTEPx5jCAwAAPgdMkAAANgEQ2BeDoCWLl3q8RM2bdo0BS8PAAC8hfjHywFQ8+bNPY484+LiUvDyAAAAqTQAunnz5p3vCQAA+FcYAvMcRdAAAMDv3FYRdFRUlKxbt06OHTsm169fd7vWvXt3b/UNAACkANPg72AAtHPnTmnYsKFcvXrVBEI5cuSQv/76SzJmzCihoaEEQAAAWIQhsDs4BNarVy9p0qSJnD9/XoKCgmTLli1y9OhRqVixoowaNSqlTwcAAJD6A6Bdu3ZJnz59JF26dOaIiYmR/Pnzy8iRI+W11167M70EAAD/KI2XDztLcQAUEBDgSrHlzp3b1AGpbNmyuW4DAIC7L22aNF497CzFNUAVKlSQ7du3S7FixaRmzZoyePBgUwM0a9YsKVu27J3pJQAAgJUZoKFDh0qePHnM7XfeeUdCQkKkU6dOEhERIVOmTPFm3wAAQApo0sabh52lOANUqVIl1+1cuXLJsmXLvN0nAACAO4rNUAEAsAmmwd/BAKhw4cK3/IAPHz6c0qcEAABeQPxzBwOgnj17ut2PjY01iyMuX75c+vXrl9KnAwAASP0BUI8ePZI8/9FHH5nZYQAAwBp2n7qeKjdDbdCggSxcuNBbTwcAAFKIWWAWBEBffvml2RcMAAD4p/Xr15vtsvLmzWvqhZcsWeJWMjNgwACzZmCmTJlMmxdeeEFOnjzp9hy6w0S3bt0kZ86cpl3Tpk3lxIkTbm0uXLggrVu3Nosw66G3L168eOcXQoxfBO1wOOT06dNy9uxZmThxYkqfDgAA2GQWWFRUlJQrV05eeuklefLJJ92u6SbqP/30kwwaNMi00SBG64o1wIlfQqPnvv76a5k/f75Za1C332rcuLHs2LHDbMGlWrVqZYIirT9WHTp0MEGQPu6OBUDNmjVz+4DTpk1r1gOqUaOGlChRIqVPBwAAbKJBgwbmSIpmalauXOl2bvz48fLQQw+ZrbQKFCggly5dkmnTppndJerUqWPazJ492+w5umrVKqlXr57s37/fBD66GXt4eLhpM3XqVKlataocOHBAihcvfmcCoCFDhkhq92S5e63uAmALwZW7Wt0FwBaid07wrbqWu0QDHk2qZM+e3dzXLI8OldWtW9fVRofKypQpI5s2bTIB0ObNm00w5Qx+VJUqVcw5bXPHAiBNP506dUpCQ0Pdzp87d86ci4uLS+lTAgCAVDgEFhMTY474AgMDzfFvXbt2TV599VUznJU1a1ZzTktqMmTIIMHBwW5tdfN1veZskzAGUXrO2eaOBIta85MU/YC00wAAwB6GDRvmKjR2Hnru39IszzPPPCM3b970qH5YY4/4wV1SgV7CNl7LAI0bN871op988olkzpzZdU2zPlr5TQ0QAADWSevlGuiBAwdK79693c792+yPBj8tWrSQI0eOyJo1a1zZHxUWFibXr183BdLxs0C64Xq1atVcbc6cOZPoeXUylmaKvB4AjRkzxhVhffzxx65KbKWZn0KFCpnzAADAHgFQoJeGuxIGP7///rusXbvWzPKKr2LFihIQEGCKpbWd0rKbvXv3ysiRI819LXbW2qFt27aZAmq1detWc84ZJHk1ANJITdWsWVMWLVqUaHwOAAD4t8jISDl48KBb7LBr1y6zTqAWMz/11FNmKvw333xjRo+cNTt6XZMpOsTWrl07M/VdgyM937dvX7N2kHNWWMmSJaV+/frSvn17mTx5smsavE6V97QA+raKoDViAwAAqY/V6wBt377dJEqcnMNnbdq0MbPIly5dau6XL18+UWyhy+k4R5zSp09vMkDR0dFSu3ZtmTFjhtvI05w5c6R79+6u2WK6ltCECSmbaZfGkVxVczI0eqtUqZKp3I7v/fffN+moL774Qqx27YbVPQDsgWnwgG9Ng+/3zQGvPt/7jT3PqPiaFM8CW7dunTRq1CjReU1HaSE0AABAapf+dsb3kprurkVLly9f9la/AABACtl9A1NLM0C6GuOCBQsSndc9O0qVKuWtfgEAAKSeDJBuYqYbnB06dEhq1aplzq1evVrmzp1rdoQHAADWSEsK6M4FQFpprdvbDx061AQ8QUFBZlfXhIsZAQCAu8vX9gLzqQBIaRG0sxD64sWLZjqabl//888/sxcYAACwb7CoGZ/nn3/eLGykc+8bNmxo5v8DAABr6AiYNw87S1EG6MSJE2Yxok8//VSioqLMIkW6rPXChQspgAYAwGLUAN2BDJBmeDTI+eWXX2T8+PFy8uRJ8xUAAMC2GaAVK1aYZac7deokRYsWvbO9AgAAKUYC6A5kgDZs2CBXrlwx22CEh4ebuh/deh4AAMC2AZBuPz916lSzLX3Hjh3Nwof58uWTmzdvmm3rNTgCAADWSZvGu4edpXgWWMaMGaVt27ayceNG2bNnj9myfvjw4RIaGmrWCAIAANYVQXvzsLN/tWZS8eLFZeTIkWZ22Lx587zXKwAAgNS2EGJC6dKlk+bNm5sDAABYw+ZJm9QXAAEAAOvZvW7Hm9g2BAAA+B0yQAAA2EQaIQXkKTJAAADA75ABAgDAJqgB8hwBEAAANkEA5DmGwAAAgN8hAwQAgE2kYSEgjxEAAQBgEwyBeY4hMAAA4HfIAAEAYBOMgHmOAAgAAJuw+w7u3sQQGAAA8DtkgAAAsAmKoD1HBggAAPgdMkAAANgEJUCeIwACAMAm0rIbvMcYAgMAAH6HDBAAADbBEJjnyAABAGCjWWDePFJq/fr10qRJE8mbN6/Zl2zJkiVu1x0OhwwZMsRcDwoKkho1asi+ffvc2sTExEi3bt0kZ86ckilTJmnatKmcOHHCrc2FCxekdevWki1bNnPo7YsXL6aorwRAAADAK6KioqRcuXIyYcKEJK+PHDlSRo8eba7/+OOPEhYWJo8//rhcuXLF1aZnz56yePFimT9/vmzcuFEiIyOlcePGEhcX52rTqlUr2bVrlyxfvtwceluDoJRI49BwzGau3bC6B4A9BFfuanUXAFuI3pl0QOBtU7Yc9erzdahS8LYfqxkgDWSaN29u7mu4oZkfDXAGDBjgyvbkzp1bRowYIR07dpRLly5Jrly5ZNasWdKyZUvT5uTJk5I/f35ZtmyZ1KtXT/bv3y+lSpWSLVu2SHh4uGmjt6tWrSq//vqrFC9e3KP+kQECAAB33JEjR+T06dNSt25d17nAwECpXr26bNq0ydzfsWOHxMbGurXRoKlMmTKuNps3bzbDXs7gR1WpUsWcc7bxBEXQAADYhLeLoGNiYswRnwYteqSUBj9KMz7x6f2jR4+62mTIkEGCg4MTtXE+Xr+GhoYmen4952zjCTJAAADYaDNUbx7Dhg1zFRo7Dz33b+jQWHw6NJbwXEIJ2yTV3pPniY8ACAAAJGngwIGmLif+oeduhxY8q4RZmoiICFdWSNtcv37dzPK6VZszZ84kev6zZ88myi7dCgEQAAA2oQkQbx6BgYGSNWtWt+N2hr9U4cKFTfCycuVK1zkNdtatWyfVqlUz9ytWrCgBAQFubU6dOiV79+51tdFiZw3Etm3b5mqzdetWc87ZxhPUAAEAYBNWZzUiIyPl4MGDboXPOkU9R44cUqBAATMDbOjQoVK0aFFz6O2MGTOaae1Kh9jatWsnffr0kZCQEPO4vn37StmyZaVOnTqmTcmSJaV+/frSvn17mTx5sjnXoUMHM1Xe0xlgigAIAAB4xfbt26VmzZqu+7179zZf27RpIzNmzJD+/ftLdHS0dO7c2Qxz6UyuFStWSJYsWVyPGTNmjKRPn15atGhh2tauXds8Nl26dK42c+bMke7du7tmi+liicmtPZQc1gECkCzWAQJ8ax2gmduPe/X52lTKL3ZldbYMAADgrmMIDAAAm2AvVM8RAAEAYBO6dg88wxAYAADwO5YGQDdu3JCZM2emaOlqAACQtDRePuzM0gBIp7l16tQp0T4jAADA+oUQ7czyITBdA0AXSQIAAPCbImhdDEkXSjp+/LhZAjtTpkxu1x944AHL+gYAgC9JyWag/s7yAKhly5bmq67oGP8/0Lmra1xcnIW9AwDAd1g+rONDLA+AdJ8QAAAAvwqAChYsaHUXAACwBYbAfCxbNmvWLHn44Yclb968cvToUXNu7Nix8tVXX1ndNQAAYEOWB0CTJk0yRdANGzaUixcvump+smfPboIgAADgGdYB8qEAaPz48TJ16lR5/fXX3ba6r1SpkuzZs8fSvgEA4GtDYN487CxtaiiCrlChQqLzgYGBEhUVZUmfAACAvVkeABUuXDjJhRC/++47KVWqlCV9AgDAV3+pe/OwM8tngfXr10+6dOki165dM2v/bNu2TebNmyfDhg2TTz75xOruAQDgM+w+bGWrAOill14ym6L2799frl69Kq1atZJ8+fLJhx9+KM8884zV3QMAADZkeQCk2rdvb46//vpLbt68KaGhoVZ3CQAAn0P+x8cCIBURESEHDhxwVZ7nypXL6i4BAACbsrzG6fLly9K6dWuzCGL16tXlscceM7eff/55uXTpktXdAwDAZ2gJkDcPO7M8AHr55Zdl69at8u2335qFEDXo+eabb2T79u1mWAwAAHgmraTx6mFnlg+BaeDz/fffyyOPPOI6V69ePbM4Yv369S3tGwAAsCfLA6CQkBDJli1bovN6Ljg42JI+AQDgi+w+bGWrIbA33njD7AV26tQp17nTp0+b9YEGDRpkad8AAPAlabz8z84syQDp1hfxF2v6/fffpWDBglKgQAFz/9ixY2YrjLNnz0rHjh2t6CIAALAxSwKg5s2bW/GyAADYGkNgqTwAevPNN614WQAAbM3uM7dsVQTttGPHDtm/f78ZGtNNUJPaIR4AAMAWAZCuAK17fv3www+SPXt2syGqrgVUs2ZNmT9/PitCAwDgIYbAfGgWWLdu3cxq0Pv27ZPz58/LhQsXZO/eveZc9+7dre4eAACwIcszQMuXL5dVq1ZJyZIlXed0COyjjz6SunXrWto3AAB8CRkgHwqAdPf3gICAROf1nF4DAACesfvaPbYaAqtVq5b06NFDTp486Tr3559/Sq9evaR27dqW9g0AANiT5QHQhAkT5MqVK1KoUCG5//77pUiRIlK4cGFzbvz48VZ3DwAAn5E2jXcPO7M8AMqfP7/89NNPZlPUnj17msLnZcuWmWnx9957r9XdAwDAZ1i5FcaNGzfM9laaxAgKCpL77rtP3n77bbdyFp3pPWTIEMmbN69pU6NGDTMJKr6YmBgzQSpnzpySKVMmadq0qZw4cUJsVwPk9Pjjj5sDAAD4nhEjRsjHH38sM2fOlNKlS8v27dvlpZdeMpuba6mLGjlypIwePVpmzJghxYoVk3fffdf87j9w4IBkyZLFtNFkyNdff22WwtEN0/v06SONGzc2iZF06dL5fgZo69at8t1337md++yzz0zkGBoaKh06dDBRIAAA8HwWmDePlNi8ebM0a9ZMGjVqZMpannrqKTObWwMhZ/Zn7Nix8vrrr8sTTzwhZcqUMcHS1atXZe7cuaaNrgM4bdo0+eCDD6ROnTpmUeTZs2fLnj17zIxxb7IsANIU2O7du1339c21a9fOvOFXX33VRH/Dhg2zqnsAAPi9mJgYsy5f/CO55MQjjzwiq1evlt9++83c//nnn2Xjxo3SsGFDc//IkSNy+vRptyVudOPz6tWry6ZNm8x9zfLExsa6tdHhMg2WnG18PgDatWuX2ywvTXWFh4fL1KlTpXfv3jJu3Dj5/PPPreoeAAA+x9s1QMOGDTNDWPGP5JITAwYMkGeffVZKlChhlrLR7I0OZ+k5pcGPyp07t9vj9L7zmn7NkCGDBAcHJ9vG52uAdMXn+B/CunXrpH79+q77lStXluPHj1vUOwAAfI+3Z24NHDjQJCXi06xNUhYsWGCGq3Q4S2uANNGhAZBmcNq0aeNqp3t+xqdDYwnPJeRJG5/JAGnwo+kwdf36dTMTrGrVqq7rOg0+qQUSAQDA3REYGChZs2Z1O5ILgPr162dKWHR/z7Jly0rr1q3Nmn7OjFFYWJj5mjCTo3uCOhMi2kZjAk2SJNfG5wMgzfboB7VhwwYTYWbMmFEeffRR13WtD9J1geAbPp8/V576TxOp9tCD5mjdqqVs3LDOdX3VyhXySvt2Uv3hcClXurj8un9/oud4e8hgaVS/jjz04ANS45Eq0qNrJzly+NBdfifA3dW3bV3ZOLufRGwcJUdXD5PPR7eXogVD3do0q1VOln7URY6vGS7ROyfIA8XyJXqeDAHpZfSAp02bvzZ9IF+M7Sj5QrO7tfn127fM4+Mf73RvesffI/xjGvzVq1clbVr3sEJnbTmnweskJw1wVq5c6bquwY6OAFWrVs3cr1ixokl+xG9z6tQps0eos43PD4Hp1DetAtfip8yZM5tKcB33c/r000/ZC8yHhOYOkx69+kr+AgXM/a+/WiI9unaRBQsXS5EiRSU6+qqUr1BB6tarL2+9+UaSz1GqVGlp1LiJhOXJI5cvXZJJH403QdOyFau9OvURSE0efbCIfLxgvezYd1TSp08nQ7o0kW8mdZUKT7wrV69dN20yBmWQzT8fkkWrfpJJg59L8nne7/ekNHqsjLwwcLqcvxglw3v/RxaOe0WqtRohN286XO3emviNTF/0X9f9yKvMtrUTK/cCa9Kkibz33ntSoEABMwS2c+dOM+W9bdu2/+tbGjMkNnToUClatKg59LYmQFq1amXaaI2RTojSqe86BT5HjhzSt29fk1HSSVK2CIBy5cplsj865U0DoIS/4L744gtzHr6hRs1abve79egln8+fJ7t/3mUCoCZNm5vzf/6Z/GJWT7Vo6bqdL9+90rV7T3n6iWZy8s8/XYEVYDfNuk50u99xyGyTxalQKr/896e/M6Dzvv3RfC2QJ0eSz5E18z3yYvOq0u6Nz2Tt1gPmXNs3PpPfv3tHaoWXkFWb/z/jGhl1Tc6cu3IH3xH81fjx42XQoEHSuXNnM2SltT8dO3aUwYMHu9r0799foqOjTRsd5tLJTytWrHCtAaTGjBkj6dOnlxYtWpi2OmFK1w3y9h/Cli+EqNFeUjTqg2+Ki4uTFd8vN1mfcuUq3NZzaCr1q8WLJN+997rGjQF/oMGMunDpqsePqVCygBkCix/onDp7SfYdOilVyhV2O9/7xcfl1fYN5MSZC7Jo5U4ZM3OVxN6I8/K7gFWs3L0iS5YsZp0fPZKjWSBdBkeP5Nxzzz0mmLrT22FZHgDBPn7/7YC0bvWMXL8eY1KaY8Z9JPcXKZKi51gwb46M+WCUCZ4K33efTJ46XQLiDY0Cdjeiz5Py358Oyi+HTnn8mLCQrBJzPVYuXol2Ox9x7orkDsnquv/R3B9k56/H5eLlq1KpTEF5u1tTKZQvRDq//fcidIA/8fkASBdkSrgokyNdYLJV6rhzChUqLJ8vXCJXrlw2Rc+DXhsg02bMTlEQ1LBxU6lS7WH56+xZmTl9mvTr01Nmzp7H/yf8wphXW0jZonml9ktjvPJ8+tf2/1f/iIyfs9Z1e+/vJ+Xi5WiZN+pleePDr+T8pSivvCasldbKIiAfY/lmqP9WUos0vT+CFaStoJmaAgULSukyZaVHrz5SrHgJmTP7sxSnUAsWLCQVK1WWD8aMkyNHDsuaVf8/GwCwK53B1bh6WanXfpz8GXExRY89fe6yBGYIkOxZgtzO58qRWSLOXU72cdt2/70Uyf35c95mr5HapPHyYWc+HwDpFHotpI5/9Bsw0Opu4X8LV8Vev/5vn8RMkwTsbMyAp81U9/odx8nRk+dS/Pid+4/J9dgbUrtKCde5sJxZpfT9eWXLz38HOUkpVyK/+Xr6r+SDJMCuLBkCW7p0qcdtmza99RoVOjSScHjk2o3b7hpu07ixo+WRRx+T3GFhcjUqSpZ/t0y2/7hNJk7+xFy/dPGiWcvh7NkIc/+PP/7+oZwzZ07JmSuXnDh+XL5fvkyqVntYgoNzSETEGZk+baoEBt4jjzxW3dL3BtxJYwe2kJYNKsnTvaaYGVq5Q/6eDXMp8ppci4k1t4OzZpT8YcGSJ/TvSSPFCv29INyZc5fNjK7LkddkxpLNMrz3E3LuUpQpoB7W6z+y9+BJWbP1V9M2/IHC8lDZQrLux9/Mc1cqXUBG9n1Svv5htxw/7b7oHHyY3dM2XpTGoX+m32UJF0q61fi1zihKKQKgu+/NQa/Jti1bTICTOUsWKVasuLzUrr0JaJTO6Br8RuLM3Cudu0qnLt1MwPPW4Dfkl1/2yeVLlyUkZ4hUrFhJOnbqIoUK32fBO4IKrtzV6i7Yni5GmJT2g2fJ7K+3mtvPNwmXqW+3TtTm3Y+XyXuTl5nbgRnSm6CnRf1KEhQYIGu3HZCewxbIiTN/D6eVL3GvfDiwpRQrnFsCA9LLsVPn5Yvvf5LRM1dK9LW/Ay3c/f9nb9t66JJXny/8/qRnatuBJQHQnUYABHgHARDgHQRAqY/PzwIDAAB/YxKYjwVAUVFRZi+QY8eOJSp47d69u2X9AgDAlxD/+FAApHuFNGzY0Kz8q4GQrgD9119/mYX0QkNDCYAAAID9psH36tXLbKB2/vx5CQoKki1btsjRo0fNjrCjRo2yunsAAPgOFgLynQBo165dZtdX3eRMD13VOX/+/DJy5Eh57bXXrO4eAACwIcsDoICAADPdXeXOndvUASld0dl5GwAA/LM0Xv5nZ5bXAFWoUEG2b98uxYoVk5o1a8rgwYNNDdCsWbOkbNmyVncPAACfwSwwH8oADR06VPLkyWNuv/POOxISEiKdOnWSiIgImTJlitXdAwAANmR5BqhSpUqu27ly5ZJly/5e1RQAAKQMCSAfCoAAAICXEAH5TgBUuHBhVxF0Ug4fPnxX+wMAAOzP8gCoZ8+ebvdjY2PN4ojLly+Xfv36WdYvAAB8jd1nbtkqAOrRo0eS5z/66CMzOwwAAMB2s8CS06BBA1m4cKHV3QAAwGdoRYk3DzuzPAOUnC+//NLsCwYAADxj85jFfgshxi+Cdjgccvr0aTl79qxMnDjR0r4BAAB7sjwAatasmVsAlDZtWrMeUI0aNaREiRKW9g0AAJ9CCsh3AqAhQ4ZY3QUAAGyBWWA+VAStO8DrthcJnTt3zlwDAACwXQZIa36SEhMTIxkyZLjr/QEAwFfZfeaWLQKgcePGma9a//PJJ59I5syZXdfi4uJk/fr11AABAAB7BUBjxoxxZYA+/vhjt+EuzfwUKlTInAcAAJ4hAeQDAdCRI0fM15o1a8qiRYskODjYqq4AAGAPREC+UwO0du1aq7sAAAD8jOWzwJ566ikZPnx4ovPvv/++PP3005b0CQAAX50G781/dmZ5ALRu3Tpp1KhRovP169c3hdAAAMAz7AXmQwFQZGRkktPdAwIC5PLly5b0CQAA2JvlAVCZMmVkwYIFic7Pnz9fSpUqZUmfAADwRWm8fKTUn3/+Kc8//7yEhIRIxowZpXz58rJjxw7XdZ35rTtA5M2bV4KCgsy2V/v27Uu0DmC3bt0kZ86ckilTJmnatKmcOHFCbFcEPWjQIHnyySfl0KFDUqtWLXNu9erVMm/ePPniiy+s7h4AAL7DwmGrCxcuyMMPP2xmd3/33XcSGhpqfrdnz57d1WbkyJEyevRomTFjhhQrVkzeffddefzxx+XAgQOSJUsW06Znz57y9ddfm0SIBlJ9+vSRxo0bm0DKmztEpHEktxTzXfTtt9/K0KFDZdeuXSYifOCBB+TNN9+U6tWr39bzXbvh9S4Cfim4cleruwDYQvTOCXfldfafivLq85XMk8njtq+++qr897//lQ0bNiR5XcMNzfxogDNgwABXtid37twyYsQI6dixo1y6dMlsiD5r1ixp2bKlaXPy5EnJnz+/LFu2TOrVq2efITClRdD6oUVFRclff/0la9asMcGPBkQAACD1zwJbunSpVKpUyczg1uxPhQoVZOrUqW7r/50+fVrq1q3rOhcYGGh+32/atMnc1yxPbGysWxsNmrRcxtnGVgFQfBr9TZw4UR588EGpWLGi1d0BAMBvxcTEmAlJ8Q89l5TDhw/LpEmTpGjRovL999/LK6+8It27d5fPPvvMXNfgR2nGJz6977ymX3ViVMLFkeO3sV0ApFmf5557TvLkySPjx4+Xhg0byvbt263uFgAAfjsNftiwYZItWza3Q88l5ebNmyZ5oSUtmv3RIa327duboMi9j2kSDY0lPJeQJ218qghaq7q1EOrTTz81w18tWrQwqa+FCxcyAwwAAItroAcOHCi9e/d2O6fDVknRBEbC390lS5Y0v9NVWFiY+aqZHG3rFBER4coKaZvr16+bgur4WSBtU61aNXtkgDTDox/UL7/8YjI+WuSkXwEAQOoQGBgoWbNmdTuSC4B0BpjO5orvt99+k4IFC5rbhQsXNgHOypUrXdc12NEFkZ3BjZa+6DqA8ducOnVK9u7d6/UAyLIM0IoVK8zYYKdOncx4IQAA8N1p8L169TJBig6B6YjOtm3bZMqUKeYwXUuTxswA0+v6e18Pva3rBbVq1cq00SG2du3amanvOgU+R44c0rdvXylbtqzUqVPHHgGQTpPToS+tGC9RooS0bt3aNeUNAACknJX7d1WuXFkWL15shs3efvttk/EZO3asqe916t+/v0RHR0vnzp3NMFd4eLhJiDjXAFJjxoyR9OnTmyBK29auXduUy3hzDaBUsQ7Q1atXzWJHGgxptBgXF2cWSWrbtq3bB5ISrAMEeAfrAAG+tQ7Q72eivfp8RXMHiV1ZHgDFp2OH06ZNMwsgXbx40awOqesKpBQBEOAdBECAbwVAByO8GwAVCbVvAJRqpsGr4sWLm2WydXaYboUBAABwJ1i+F1hSdJyvefPm5gAAAKm+BtrnpMoACAAA3AYiIN8cAgMAALgbyAABAGATVk6D9zUEQAAA2ISXt8uyNYbAAACA3yEDBACATZAA8hwZIAAA4HfIAAEAYBekgDxGAAQAgE0wC8xzDIEBAAC/QwYIAACbYBq85wiAAACwCeIfzzEEBgAA/A4ZIAAAbIIhMM8RAAEAYBtEQJ5iCAwAAPgdMkAAANgEQ2CeIwMEAAD8DhkgAABsggSQ5wiAAACwCYbAPMcQGAAA8DtkgAAAsAk2Q/UcARAAAHZB/OMxhsAAAIDfIQMEAIBNkADyHBkgAADgd8gAAQBgE0yD9xwBEAAANsEsMM8xBAYAAPwOGSAAAOyCBJDHCIAAALAJ4h/PMQQGAAC8btiwYZImTRrp2bOn65zD4ZAhQ4ZI3rx5JSgoSGrUqCH79u1ze1xMTIx069ZNcubMKZkyZZKmTZvKiRMnvN4/AiAAAGw0C8ybx+368ccfZcqUKfLAAw+4nR85cqSMHj1aJkyYYNqEhYXJ448/LleuXHG10YBp8eLFMn/+fNm4caNERkZK48aNJS4uTryJAAgAABvNAvPmv9uhActzzz0nU6dOleDgYLfsz9ixY+X111+XJ554QsqUKSMzZ86Uq1evyty5c02bS5cuybRp0+SDDz6QOnXqSIUKFWT27NmyZ88eWbVqlXgTARAAAPCaLl26SKNGjUwAE9+RI0fk9OnTUrduXde5wMBAqV69umzatMnc37Fjh8TGxrq10eEyDZacbbyFImgAAGzC2wshxsTEmCM+DVr0SIoOW/30009meCshDX5U7ty53c7r/aNHj7raZMiQwS1z5GzjfLy3kAECAADJFjJny5bN7dBzSTl+/Lj06NHDDFndc889twjS3KM0HRpLeC4hT9qkFAEQAABI0sCBA01dTvxDzyVFh68iIiKkYsWKkj59enOsW7dOxo0bZ247Mz8JMzn6GOc1LYq+fv26XLhwIdk23kIABACATXh7FlhgYKBkzZrV7Uhu+Kt27dqmWHnXrl2uo1KlSqYgWm/fd999JsBZuXKl6zEa7GiQVK1aNXNfg6eAgAC3NqdOnZK9e/e62ngLNUAAAOBfy5IliylWjk/X8QkJCXGd1ynuQ4cOlaJFi5pDb2fMmFFatWplrusQW7t27aRPnz7mcTly5JC+fftK2bJlExVV/1sEQAAA2ERq3wy1f//+Eh0dLZ07dzbDXOHh4bJixQoTPDmNGTPGDJm1aNHCtNXM0owZMyRdunRe7Usah1YW2cy1G1b3ALCH4Mpdre4CYAvROyfclde5fO2mV58v6z32rZSx7zsDAABIBkNgAADYROoeAEtdyAABAAC/QwYIAAC7IAXkMQIgAABsIrXPAktNGAIDAAB+hwwQAAA24e3NUO2MAAgAAJsg/vEcQ2AAAMDvkAECAMAuSAF5jAwQAADwO2SAAACwCabBe44ACAAAm2AWmOcYAgMAAH4njcPhcFjdCfifmJgYGTZsmAwcOFACAwOt7g7gk/g+Am4fARAscfnyZcmWLZtcunRJsmbNanV3AJ/E9xFw+xgCAwAAfocACAAA+B0CIAAA4HcIgGAJLdh88803KdwE/gW+j4DbRxE0AADwO2SAAACA3yEAAgAAfocACC5DhgyR8uXLu+6/+OKL0rx587vejz/++EPSpEkju3btktSuUKFCMnbsWKu7gVTG376XrHp/wL9BAJTK6Q8W/QGmR0BAgNx3333St29fiYqKuuOv/eGHH8qMGTNSZdBSo0YN1+eiBaD58uWTJk2ayKJFi+7K68P38L2UtMOHD8uzzz4refPmlXvuuUfuvfdeadasmfz222935fUBqxAA+YD69evLqVOnzA+qd999VyZOnGh+cCclNjbWa6+rK8xmz55dUqv27dubz+XgwYOycOFCKVWqlDzzzDPSoUOHWz7Om58RfAvfS+6uX78ujz/+uFlRWv94OHDggCxYsEDKlCljVpe2ks7PuXHjhqV9gL0RAPkAzXCEhYVJ/vz5pVWrVvLcc8/JkiVL3FLtn376qfmLVtvqDw794aWBQGhoqFkiv1atWvLzzz+7Pe/w4cMld+7ckiVLFmnXrp1cu3btlmntmzdvyogRI6RIkSLmdQoUKCDvvfeeuVa4cGHztUKFCuavV83QOE2fPl1Klixp/rosUaKE+aUT37Zt28zj9HqlSpVk586dHn0uGTNmdH0uVapUMX2bPHmyTJ06VVatWuX21/Tnn39u+qSvMXv27ERDFEqHsnRIK+H7HzVqlOTJk0dCQkKkS5cut/zFqO9Vf9mtXLnSo/eAu4vvJXe//PKLCQb1efR7qGDBgvLwww+bvlSuXNnVbs+ePeZ9BwUFme8D/TwiIyMTPd9bb73l+pw6duxoAiwn/SxHjhxpPlt9nnLlysmXX37puv7DDz+Y9/v999+bvuvnsmHDhlv2H/g3CIB8kP7wiP9LWDMg+gtesyDOtHmjRo3k9OnTsmzZMtmxY4c8+OCDUrt2bTl//ry5ru11/RD9Qbd9+3bzCz7hD9OEdMNF/aE9aNAg84Nz7ty55oe+8wev0sBD/8J2DkVpMPL666+b19m/f78MHTrUPH7mzJnmug4/NG7cWIoXL276qb+EkvuL3BNt2rSR4ODgRENhAwYMkO7du5s+1KtXz+PnW7t2rRw6dMh81T7rMEZyQxkaKGnf9Qe4/lWN1M/fv5dy5coladOmNYFIXFxckm2uXr1qMmf6ffXjjz/KF198YfrWtWtXt3arV682/dLvlXnz5snixYtNQOT0xhtvmABu0qRJsm/fPunVq5c8//zzsm7dOrfn6d+/v9ngVZ/rgQceuGX/gX9F1wFC6tWmTRtHs2bNXPe3bt3qCAkJcbRo0cLcf/PNNx0BAQGOiIgIV5vVq1c7smbN6rh27Zrbc91///2OyZMnm9tVq1Z1vPLKK27Xw8PDHeXKlUvytS9fvuwIDAx0TJ06Ncl+HjlyRNeTcuzcudPtfP78+R1z5851O/fOO++Y11fanxw5cjiioqJc1ydNmpTkc8VXvXp1R48ePZK8pu+jQYMGbv0aO3asWxv93OK/VzVmzBhHwYIF3d6/3r9x44br3NNPP+1o2bKl675e18e9+uqrjjx58jh2796dbJ9hLb6XkjZhwgRHxowZHVmyZHHUrFnT8fbbbzsOHTrkuj5lyhRHcHCwIzIy0nXu22+/daRNm9Zx+vRp1/tL6rUzZ87siIuLM4+95557HJs2bXJ77Xbt2jmeffZZc3vt2rWmr0uWLEm2r4A3pf934RPuhm+++UYyZ85sxsP1r1UtUBw/frzruqat9S85J/3rT9PTmqqOLzo62mQzlP519corr7hdr1q1qvnrLSnaPiYmxvzl66mzZ8/K8ePHzZCA1us46fvQYSLn82oqXIez4vfj39BUu6bS49OU+u0oXbq0pEuXznVf/7rX4YD4PvjgA/PXt/71r+l9pF58LyWmw7ovvPCC6e/WrVtNhkezS0uXLjWZTOfzZsqUyfUYHSbTYTytGXJmrpJ6bf3stN8RERFmWDBhZlSHyHTIzhvfq0BKEQD5gJo1a5q0sc5c0Zka+jW++D+YlP5g0l/UOqae0O0WYupQQUppP5yp+/DwcLdrzqDC2wuRaxr/999/d6tfSOoz0rR/wtdOqrYn4WetgZXzfTk9+uij8u2335qhkFdffdUL7wJ3Ct9LSdPapaZNm5pDi8N1mFi/asCS1B8UTsmdT9jG2X/9PtEZm/El3MYj4f8BcKcQAPkA/YGgxZKe0hoFrVlInz69W1FvfFpIuWXLFvOXn5PeT07RokXND24d53/55ZcTXc+QIYP5Gr+OQP8y1B92WmSpxaZJ0Zlbs2bNMn9RO38x3Kof/0TrIS5cuCBPPvnkLdvpX/n6GcX/4X67044feugh6datm/mlob+M+vXrd1vPgzuP76V/pt8PWmC9adMm1/Pq95VmOZ3ByX//+1/zR0SxYsVcj9PC8ISvrdk2nVav9UMa6Bw7dkyqV6+e4j4BdwIBkA3VqVPHpJ911okWWmpR5MmTJ00Rp57TFHOPHj1MwbDefuSRR2TOnDmmMDG5IRydVaKFxFqgqD+gNQWuaXl9jKbldeaH/uBbvny5+YGn7TU1r4WYWnyss0IaNGhgUv86VKRBSu/evc1MHC3s1OfQIkmdtaXFxJ7Q4kz95aTDAH/++acpFh0zZox06tTJ/KV/KzqzRvuvs1Keeuop0+/vvvvO9PN26Oetj9diUf1lqQWe8H12/17SoF8LuFu3bm0CHe2PFiXrTDjto9KAS9voe9Q+aF814NfHOIe/nMNZztc+evSoeYwWSmugpBkmLcjW7wvNBunnpFPvNcjSIEmfG7jrvFpRhDteuJlQUsW8zkLLbt26OfLmzWsKO7WA8rnnnnMcO3bM1ea9995z5MyZ0xQq6uv0798/2cJNpcWM7777rin81ecsUKCAY+jQoa7rWtSpr6PFkVqk7DRnzhxH+fLlHRkyZDDFlI899phj0aJFruubN282r6vXtd3ChQs9KoLWNnro47QAuXHjxm7Pe6uCUmeRpvY3U6ZMjhdeeMF8HgmLoBN+9lp4Hf+9OYugndatW2ee78MPP0y277AG30uJnT171tG9e3dHmTJlTN+1ELps2bKOUaNGmT46aXG/FkhrIbMWO7dv395x5cqVRO9v8ODBprBcn+vll192Kx6/efOm+b4oXry4ec+5cuVy1KtXz3zPxC+CvnDhQrL/R4A3sRs8AADwO6wDBAAA/A4BEAAA8DsEQAAAwO8QAAEAAL9DAAQAAPwOARAAAPA7BEAAAMDvEAABAAC/QwAEwNBtDsqXL++6/+KLL5rtHu423cJB96O63b3ZAMATBEBAKqeBiAYEeuju5brHlO6rpJtT3kkffvihzJgxw6O2BC0AfA2boQI+QDdZnT59usTGxsqGDRvMLuIaAE2aNMmtnV7XIMkbdANOALArMkCADwgMDJSwsDDJnz+/2fVbd+hesmSJa9hKd+/WzJC20+39Ll26JB06dDA7i+vu4bVq1ZKff/7Z7TmHDx9udvPWnbp1F+9r1665XU84BKa7eOuO6EWKFDGvU6BAAXnvvffMtcKFC5uvFSpUMJmgGjVquB6ngVvJkiXNruYlSpSQiRMnur3Otm3bzOP0uu6ovnPnzjvyGQJAfGSAAB8UFBRksj3q4MGD8vnnn8vChQslXbp05lyjRo0kR44csmzZMpPJmTx5stSuXVt+++03c17bv/nmm/LRRx/Jo48+KrNmzZJx48aZICo5AwcOlKlTp8qYMWPkkUcekVOnTsmvv/7qCmIeeughWbVqlZQuXVoyZMhgzmt7fZ0JEyaYIEeDm/bt20umTJmkTZs2JovVuHFjE6DNnj1bjhw5Ij169LgrnyEAP+fVveUBeF2bNm0czZo1c93funWrIyQkxNGiRQvHm2++6QgICHBERES4rq9evdqRNWtWx7Vr19ye5/7773dMnjzZ3K5atarjlVdecbseHh7uKFeuXJKve/nyZUdgYKBj6tSpSfbxyJEjDv1xsnPnTrfz+fPnd8ydO9ft3DvvvGNeX2l/cuTI4YiKinJdnzRpUpLPBQDexBAY4AO++eYbyZw5sxkmqlq1qjz22GMyfvx4c61gwYKSK1cuV9sdO3ZIZGSkhISEmMc4D82uHDp0yLTZv3+/eZ74Et6PT9vHxMSYLJKnzp49K8ePHzfDa/H78e6777r1o1y5cpIxY0aP+gEA3sIQGOADatasaQqetcA5b968boXOOpwUn9bq5MmTR3744YdEz5M9e/bbHnJLKe2HcxgsPDzc7ZpzqE7rlQDACgRAgA/QIEeLjz3x4IMPyunTpyV9+vRSqFChJNtoUfKWLVvkhRdecJ3T+8kpWrSoCYJWr15tZqAl5Kz5iYuLc53TAut8+fLJ4cOHTdF2UkqVKmXqj6Kjo11B1q36AQDewhAYYDN16tQxw0g6g+v77783a/Rs2rRJ3njjDdm+fbtpo4XGOnNMDy2M1kLlffv2JfucOvQ2YMAA6d+/v3z22WdmCEsDlWnTppnrOttMA5jly5fLmTNnzCw0pbPUhg0bZtYU0tfZs2ePmRU2evRoc11ntKVNm9YMk/3yyy+maHvUqFF35XMC4N8IgACb0WnoGkhonVDbtm2lWLFi8swzz5hASLMyqmXLljJ48GAT1FSsWFGOHj0qnTp1uuXzDho0SPr06WMepxkkfY6IiAhzTbNNOotMZ5vpEF2zZs3Mec0WffLJJ2ZBxbJly0r16tXNbee0ea0J+vrrr03wo7PEXn/9dTPVHgDutDRaCX3HXwUAACAVIQMEAAD8DgEQAADwOwRAAADA7xAAAQAAv0MABAAA/A4BEAAA8DsEQAAAwO8QAAEAAL9DAAQAAPwOARAAAPA7BEAAAMDvEAABAADxN/8HC3AaxPU8gekAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "files = glob(\"results/HDC_balanced_UNDERSAMPLING_TWEAKED/20250423_130656/predictions_20250424_032714.pkl\")\n",
    "assert len(files) > 0, \"No prediction files found!\"\n",
    "file_path = files[0]\n",
    "with open(file_path, \"rb\") as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "\n",
    "# Get raw test predictions and labels\n",
    "test_probs = np.array(predictions[\"test_predictions\"])\n",
    "test_labels = np.array(predictions[\"test_ground_truth\"])\n",
    "\n",
    "# Use same threshold as during training\n",
    "threshold = 0.31  # or dynamically extract it from your saved metrics\n",
    "\n",
    "# Convert to binary predictions\n",
    "test_binary_preds = (test_probs >= threshold).astype(int)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_binary_preds)\n",
    "\n",
    "# Print it\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Predicted Drunk\", \"Predicted Sober\"],\n",
    "            yticklabels=[\"Actual Drunk\", \"Actual Sober\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8946428298950195"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['test_predictions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['test_ground_truth'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count class labels\n",
    "from collections import Counter\n",
    "test_label_counts = Counter(predictions[\"test_ground_truth\"])\n",
    "train_label_counts = Counter(predictions[\"train_ground_truth\"])\n",
    "\n",
    "print(\"Class counts in TEST set:\")\n",
    "for label, count in sorted(test_label_counts.items()):\n",
    "    print(f\"Label {int(label)}: {count}\")\n",
    "\n",
    "print(\"\\nClass counts in TRAIN set:\")\n",
    "for label, count in sorted(train_label_counts.items()):\n",
    "    print(f\"Label {int(label)}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 47562, 1.0: 25831})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 2418, 0.0: 1540})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
