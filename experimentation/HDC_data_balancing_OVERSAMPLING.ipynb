{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDC model training notebook \n",
    "\n",
    "Steps:\n",
    "- load raw data \n",
    "- generate configs (hyper parameter)\n",
    "- do cross validation to find the best configs (hyper parameters)\n",
    "- train the model with the best hyperparameters in entire data from cross validation step \n",
    "- evaluate the model with test data (not included in cross validation train/val set)\n",
    "- save the model and result\n",
    "\n",
    "Note:\n",
    "in this notebook, the final performance of the model is evaluated with test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='HDC_balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1732869081399
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd/__init__.py\n",
      "/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd/embeddings.py\n",
      "/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd/models.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "import builtins\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Use local Executorch compatible copy of TorchHD\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"../../../torchhd\"))\n",
    "sys.path.insert(0, os.path.abspath(\"../../../torchhd/torchhd\"))\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "from torchhd import models\n",
    "print(torchhd.__file__) #Check\n",
    "print(embeddings.__file__) #Check\n",
    "print(models.__file__) #Check\n",
    "from typing import Union, Literal\n",
    "import json \n",
    "import pickle\n",
    "# import torchmetrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "from glob import glob\n",
    "import polars as pl \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Remove torchhd if already loaded\n",
    "if \"torchhd\" in sys.modules:\n",
    "    del sys.modules[\"torchhd\"]\n",
    "\n",
    "# Point to the actual package folder (the one with __init__.py)\n",
    "sys.path.insert(0, os.path.abspath(\"/Users/jofremosegui/Desktop/TFG/wearbac_experiments/torchhd/torchhd\"))\n",
    "\n",
    "# Now import\n",
    "import torchhd\n",
    "from torchhd import embeddings, models\n",
    "\n",
    "# Sanity check\n",
    "print(torchhd.__file__)\n",
    "assert hasattr(models.Centroid, \"add_adjust\"), \"Custom torchhd still not loaded correctly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(models.Centroid, \"add_adjust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_COLUMNS = ['user_id', 'ZTIME', 'ZVALUEX_acc', 'ZVALUEY_acc', \n",
    "               'ZVALUEZ_acc', 'ZVALUEX_gyro', 'ZVALUEY_gyro', 'ZVALUEZ_gyro', 'ZHEARTRATE', 'ZAVERAGEHEARTRATE', \n",
    "              'tac (ug/L)', 'tac_flg', 'session_id']\n",
    "\n",
    "TAC_THRESHOLD = 35\n",
    "TAC_LEVEL_0 = 0\n",
    "TAC_LEVEL_1 = 1\n",
    "NUM_TAC_LEVELS = 2\n",
    "\n",
    "ALL_USERS = [ 6,  9, 10, 11, 14, 15, 16, 24, 25, 26, 28, 31]\n",
    "\n",
    "TRAIN_USERS = [[9, 10, 14, 15, 24, 28, 31],\n",
    "[10, 11, 6, 31],\n",
    "[6, 9, 11, 14, 15, 24, 28]]\n",
    "\n",
    "\n",
    "VALID_USERS = [[11, 6],\n",
    "[9, 14, 15, 24, 28],\n",
    "[10, 31]]\n",
    "\n",
    "TEST_USERS = [16,25,26]\n",
    "\n",
    "# base config \n",
    "BASE_CONFIGS = {\n",
    "    \"device\": \"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    \"window_size\": [40*20],\n",
    "    \"ngrams\": [7],\n",
    "    \"hdc_dimension\": 5000,\n",
    "    \"batch_size\": [64],\n",
    "    \"learning_rate\": [2],\n",
    "    \"epochs\": 10,\n",
    "    \"patience\": 5, # early stopping\n",
    "    \"overlap_ratio\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(preprocess_fld='../../Preprocessed_all'):\n",
    "    file_paths = sorted(glob(preprocess_fld + '/after_preprocess_group*.csv'))\n",
    "    df_final = [pl.read_csv(file_path, columns=RAW_COLUMNS) for file_path in file_paths]\n",
    "    # get the same columns from all the dataframes\n",
    "    columns = df_final[-1].columns\n",
    "    # Optionally, you can concatenate the DataFrames into a single DataFrame\n",
    "    df_final = pl.concat([data_df[columns] for data_df in df_final])\n",
    "    # filter user \n",
    "    df_final  = df_final.filter(df_final['user_id'].is_in(ALL_USERS))\n",
    "    # Create new session_id such that it is unique for all users\n",
    "    df_final = (\n",
    "        df_final.with_columns([\n",
    "            pl.concat_str([\n",
    "                pl.col('user_id').cast(pl.Utf8),\n",
    "                pl.lit('_'),\n",
    "                pl.col('session_id')\n",
    "            ]).alias('combined_key')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col('combined_key').rank(method='dense').cast(pl.Int32).alias('session_id')\n",
    "        ])\n",
    "    )\n",
    "    df_final = df_final.drop('combined_key')\n",
    "    df_final = df_final.with_columns(\n",
    "        tac_flg=(df_final['tac (ug/L)'] >= TAC_THRESHOLD).cast(float)\n",
    "    )\n",
    "    return df_final.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, features, labels, window_size=10):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]),\n",
    "            torch.FloatTensor([self.labels[idx]]),\n",
    "        )\n",
    "\n",
    "class HdcGenericEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_size: int, out_dimension: int, ngrams: int = 5, dtype = torch.float32, device : str = \"cpu\"):\n",
    "        super(HdcGenericEncoder, self).__init__()\n",
    "\n",
    "        #Embeddings for raw data\n",
    "        self.input_size = input_size\n",
    "        self.keys = embeddings.Random(input_size, out_dimension, dtype=dtype, device=device)\n",
    "        self.motion_embed = embeddings.Level(3000, out_dimension, dtype=dtype, \n",
    "                                      low=-3.0, high=3.0, device=device)\n",
    "        self.hr_embed = embeddings.Level(200, out_dimension, dtype=dtype, \n",
    "                                      low=50, high=200, device=device)\n",
    "        self.ngrams = ngrams\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def batch_generic(self, id, levels, ngram):\n",
    "        batch_size = levels.shape[0]\n",
    "        multiset_list = []\n",
    "        for b in range(batch_size):\n",
    "            level = levels[b]\n",
    "            b_levels = [\n",
    "                torchhd.ngrams(level[0][i : i + ngram], ngram)\n",
    "                for i in range(1, id.shape[0] - ngram + 1)\n",
    "            ]\n",
    "            if len(b_levels) > 0:\n",
    "                b_levels = torch.stack(b_levels)\n",
    "                multiset_list.append(torchhd.multiset(torchhd.bind(id[:-ngram], b_levels)).unsqueeze(0))\n",
    "            else:\n",
    "                multiset_list.append(torchhd.multiset(torchhd.bind(id, level)))\n",
    "        return torch.stack(multiset_list)\n",
    "\n",
    "    # Encode window\n",
    "    def forward(self, channels: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, window_size, num_channels = channels.shape\n",
    "        motion_signals = channels[:, :, : self.input_size - 1]\n",
    "        hr_signals = channels[:, :, self.input_size - 1].unsqueeze(-1)\n",
    "        \n",
    "        # Use generic encoder\n",
    "        enc_motion_channels = self.motion_embed(motion_signals)\n",
    "        enc_hr_channel = self.hr_embed(hr_signals)\n",
    "        enc_channels = torch.cat([enc_motion_channels, enc_hr_channel], dim = 2)\n",
    "        sample_hvs = self.batch_generic(\n",
    "            self.keys.weight, enc_channels, self.ngrams\n",
    "        )\n",
    "        sample_hv = torchhd.multiset(sample_hvs)\n",
    "\n",
    "        sample_hv = torchhd.hard_quantize(sample_hv)\n",
    "        \n",
    "        return sample_hv\n",
    "    \n",
    "    \n",
    "class HdcModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        out_dimension: int,\n",
    "        ngrams: int = 5,\n",
    "        dtype=torch.float32,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super(HdcModel, self).__init__()\n",
    "        \n",
    "        self.encoder = HdcGenericEncoder(input_size, out_dimension, ngrams=ngrams, dtype=dtype, device=device)\n",
    "        self.centroid = models.Centroid(\n",
    "                out_dimension,\n",
    "                NUM_TAC_LEVELS,\n",
    "                dtype=dtype,\n",
    "                device=device,\n",
    "            )\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def add(self, x : torch.Tensor, y : torch.Tensor, lr : float):\n",
    "        hv = self.encoder(x)\n",
    "        labels = y.to(dtype=torch.int64)\n",
    "        for i in range(len(hv)):\n",
    "            #This operations can't be done in batches\n",
    "            self.centroid.add_adjust(\n",
    "                    hv[i].unsqueeze(0), labels[i], lr=lr\n",
    "                )\n",
    "            \n",
    "    def adjust_reset(self):\n",
    "        self.centroid.adjust_reset()\n",
    "        \n",
    "    #Executorch safe (0.6.x)\n",
    "    def vector_norm(self, x, p=2, dim=None, keepdim=False):\n",
    "        return torch.pow(torch.sum(torch.abs(x) ** p, dim=dim, keepdim=keepdim), 1 / p)\n",
    "        \n",
    "    def normalized_inference(self, input: torch.Tensor, dot: bool = False):\n",
    "        normalized_weight = self.centroid.weight.detach().clone()\n",
    "        norms = self.vector_norm(normalized_weight, p=2, dim=1, keepdim=True)\n",
    "        norms.clamp_(min=1e-12)\n",
    "        normalized_weight.div_(norms)\n",
    "\n",
    "        if dot:\n",
    "            return torchhd.functional.dot_similarity(input, normalized_weight)\n",
    "        return torchhd.functional.cosine_similarity(input, normalized_weight)\n",
    "        \n",
    "    def binary_hdc_output(self, outputs):\n",
    "        probs = F.softmax(outputs, dim=1)  # Shape: (batch_size, 2)\n",
    "        return probs[:, 1]  # Extract only class 1 probability\n",
    "        \n",
    "    def forward(self, x : torch.Tensor):\n",
    "        hv = self.encoder(x)\n",
    "        output = self.normalized_inference(hv, True)\n",
    "\n",
    "        return self.binary_hdc_output(output)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def prepare_sequences_balanced(df, window_size=10, overlap_ratio=0.1, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Generate sequences and apply oversampling to balance class distribution.\n",
    "    \"\"\"\n",
    "    session_user_map = pd.Series(df[\"user_id\"].values, index=df[\"session_id\"]).astype(int).to_dict()\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "    print(f\"Preparing balanced sequences...\")\n",
    "\n",
    "    features = df[feature_columns].values\n",
    "    labels = df[\"tac_flg\"].values\n",
    "    session_ids = df[\"session_id\"].values\n",
    "    unique_sessions = np.unique(session_ids)\n",
    "\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    sequence_user_ids = []\n",
    "\n",
    "    for session_id in tqdm(unique_sessions):\n",
    "        session_mask = session_ids == session_id\n",
    "        session_indices = np.where(session_mask)[0]\n",
    "\n",
    "        if len(session_indices) >= window_size:\n",
    "            for start_idx in range(0, len(session_indices) - window_size + 1, int(window_size * overlap_ratio)):\n",
    "                window_indices = session_indices[start_idx : start_idx + window_size]\n",
    "                if len(window_indices) < window_size:\n",
    "                    continue\n",
    "\n",
    "                sequence = features[window_indices]\n",
    "                label = stats.mode(labels[window_indices].astype(int), keepdims=False).mode\n",
    "\n",
    "                sequences.append(sequence)\n",
    "                sequence_labels.append(label)\n",
    "                sequence_user_ids.append(session_user_map[session_id])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequence_labels = np.array(sequence_labels)\n",
    "    sequence_user_ids = np.array(sequence_user_ids)\n",
    "\n",
    "    # === Perform oversampling on the minority class (label == 1)\n",
    "    print(\"Balancing sequences via oversampling...\")\n",
    "\n",
    "    sober_mask = sequence_labels == 0\n",
    "    drunk_mask = sequence_labels == 1\n",
    "\n",
    "    sober_seqs = sequences[sober_mask]\n",
    "    sober_labels = sequence_labels[sober_mask]\n",
    "    sober_users = sequence_user_ids[sober_mask]\n",
    "\n",
    "    drunk_seqs = sequences[drunk_mask]\n",
    "    drunk_labels = sequence_labels[drunk_mask]\n",
    "    drunk_users = sequence_user_ids[drunk_mask]\n",
    "\n",
    "    if len(drunk_seqs) == 0:\n",
    "        raise ValueError(\"No drunk windows found in data. Cannot balance.\")\n",
    "\n",
    "    drunk_seqs_resampled, drunk_labels_resampled, drunk_users_resampled = resample(\n",
    "        drunk_seqs,\n",
    "        drunk_labels,\n",
    "        drunk_users,\n",
    "        replace=True,\n",
    "        n_samples=len(sober_seqs),\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Combine and shuffle\n",
    "    sequences_balanced = np.concatenate([sober_seqs, drunk_seqs_resampled])\n",
    "    labels_balanced = np.concatenate([sober_labels, drunk_labels_resampled])\n",
    "    users_balanced = np.concatenate([sober_users, drunk_users_resampled])\n",
    "\n",
    "    # Shuffle\n",
    "    indices = np.arange(len(labels_balanced))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    sequences_balanced = sequences_balanced[indices]\n",
    "    labels_balanced = labels_balanced[indices]\n",
    "    users_balanced = users_balanced[indices]\n",
    "\n",
    "    print(f\"Balanced sequence shape: {sequences_balanced.shape}\")\n",
    "    print(\"Balanced label counts:\")\n",
    "    print(f\"  sober (0): {np.sum(labels_balanced == 0)}\")\n",
    "    print(f\"  drunk (1): {np.sum(labels_balanced == 1)}\")\n",
    "\n",
    "    return sequences_balanced, labels_balanced, users_balanced\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(model, valid_loader, criterion, device):\n",
    "    \"\"\"検証データでのモデル評価\"\"\"\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.squeeze(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(outputs.cpu().numpy())\n",
    "            val_labels.extend(batch_y.squeeze(-1).cpu().numpy())\n",
    "\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    val_prauc = average_precision_score(val_labels, val_preds)\n",
    "    val_rocauc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    return {\n",
    "        \"loss\": val_loss / len(valid_loader),\n",
    "        \"pr_auc\": val_prauc,\n",
    "        \"roc_auc\": val_rocauc,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model : HdcModel,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    criterion,\n",
    "    lr,\n",
    "    device,\n",
    "    epochs=100,\n",
    "    patience=5,\n",
    "):\n",
    "    best_val_prauc = 0\n",
    "    patience_counter = 0\n",
    "    best_train_epoch = 0\n",
    "    best_model_state = None\n",
    "    training_history = []\n",
    "\n",
    "    print(\n",
    "        \"Epoch | Train Loss |  Val Loss  |  Val PR-AUC  |  Val ROC-AUC  |  Epoch Time (s)\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            model.add(batch_X, batch_y, lr)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.squeeze(-1))\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        model.adjust_reset()\n",
    "\n",
    "        if valid_loader is None:\n",
    "            epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"time\": epoch_time}\n",
    "            training_history.append(epoch_results)\n",
    "            print(f\"{epoch+1:5d} | {train_loss:.6f} | ------ | ------ | {epoch_time:.2f}\")\n",
    "            continue\n",
    "    \n",
    "        val_metrics = validate_model(model, valid_loader, criterion, device)\n",
    "        epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_metrics[\"loss\"], \n",
    "                         \"val_pr_auc\": val_metrics[\"pr_auc\"], \"val_roc_auc\": val_metrics[\"roc_auc\"], \"time\": epoch_time}\n",
    "        training_history.append(epoch_results)\n",
    "\n",
    "        print(\n",
    "            f\"{epoch+1:5d} | {train_loss:.6f} | {val_metrics['loss']:.6f} | \"\n",
    "            f\"{val_metrics['pr_auc']:.4f} | {val_metrics['roc_auc']:.4f} | \"\n",
    "            f\"{epoch_time:.2f}\"\n",
    "        )\n",
    "        \n",
    "        if val_metrics[\"pr_auc\"] >= best_val_prauc:\n",
    "            best_val_prauc = val_metrics[\"pr_auc\"]\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "            best_train_epoch = epoch\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after epoch {epoch+1}\")\n",
    "            print(f\"Best validation PR-AUC: {best_val_prauc:.4f}\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None: \n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model, training_history, best_train_epoch\n",
    "\n",
    "\n",
    "def inference_dataset(model, data_loader, device, pred_threshold=None):\n",
    "    \"\"\"evaluation model after a fold training\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            labels.extend(batch_y.squeeze(-1).cpu().numpy())\n",
    "\n",
    "    pred_prob = np.array(predictions)\n",
    "    gt_labels = np.array(labels)\n",
    "    return pred_prob, gt_labels\n",
    "\n",
    "\n",
    "def performance_calculation(pred_prob, gt_label, threshold=None):\n",
    "    '''\n",
    "    Calculate the performance of the model\n",
    "    Args:\n",
    "    pred_prob: list, predicted probability\n",
    "    gt_label: list, ground truth label\n",
    "    threshold: float, threshold for binary classification (None if we are evaluating on train data)\n",
    "    '''\n",
    "    if threshold is None:\n",
    "        # Find the optimal threshold by maximizing F1 score\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)  # Test 99 threshold values\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5  # Default if no better threshold is found\n",
    "        \n",
    "        for t in thresholds:\n",
    "            temp_pred = (pred_prob >= t).astype(int)\n",
    "            temp_f1 = f1_score(gt_label, temp_pred)\n",
    "            \n",
    "            if temp_f1 > best_f1:\n",
    "                best_f1 = temp_f1\n",
    "                best_threshold = t\n",
    "        \n",
    "        threshold = best_threshold\n",
    "        \n",
    "    pred_label = (pred_prob >= threshold).astype(int)\n",
    "    roc_auc = roc_auc_score(gt_label, pred_prob)\n",
    "    pr_auc = average_precision_score(gt_label, pred_prob)\n",
    "    accuracy = accuracy_score(gt_label, pred_label)\n",
    "    sober_acc = accuracy_score(gt_label[gt_label == 0], pred_label[gt_label == 0])\n",
    "    drunk_acc = accuracy_score(gt_label[gt_label == 1], pred_label[gt_label == 1])\n",
    "    f1 = f1_score(gt_label, pred_label)\n",
    "    return roc_auc, pr_auc, accuracy, sober_acc, drunk_acc, f1, threshold\n",
    "\n",
    "\n",
    "def generate_configs(base_config):\n",
    "    \"\"\"\n",
    "    Generate multiple configurations from a base config.\n",
    "    For any list values in the base config, create a separate config for each list item.\n",
    "    \n",
    "    Args:\n",
    "        base_config (dict): Base configuration with potential list values\n",
    "        \n",
    "    Returns:\n",
    "        list: List of individual configurations\n",
    "    \"\"\"\n",
    "    # Find all keys with list values\n",
    "    list_keys = [key for key, value in base_config.items() if isinstance(value, list)]\n",
    "    \n",
    "    if not list_keys:\n",
    "        # If no list values found, return the original config\n",
    "        return [base_config]\n",
    "    \n",
    "    # Start with the first list key\n",
    "    key = list_keys[0]\n",
    "    values = base_config[key]\n",
    "    \n",
    "    # Generate configurations for each value of the first list key\n",
    "    configs = []\n",
    "    for value in values:\n",
    "        # Create a new config with this specific value\n",
    "        new_config = base_config.copy()\n",
    "        new_config[key] = value\n",
    "        \n",
    "        # Recursively handle any remaining list keys\n",
    "        remaining_configs = generate_configs(new_config)\n",
    "        configs.extend(remaining_configs)\n",
    "    \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_results(model, save_folder, train_preds, train_gt_labels, test_preds, test_gt_labels, metrics, config):\n",
    "    \"\"\"\n",
    "    Save model, predictions, ground truth, metrics, and model structure to the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        save_folder: Folder path to save results\n",
    "        train_preds: Training predictions\n",
    "        train_gt_labels: Training ground truth labels\n",
    "        test_preds: Test predictions\n",
    "        test_gt_labels: Test ground truth labels\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "        config: Model configuration dictionary\n",
    "    \"\"\"\n",
    "    # Create a timestamp for the save files\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(save_folder, f\"model_{timestamp}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save model architecture as text\n",
    "    model_structure_path = os.path.join(save_folder, f\"model_structure_{timestamp}.txt\")\n",
    "    with open(model_structure_path, 'w') as f:\n",
    "        f.write(str(model))\n",
    "    \n",
    "    # Save predictions and ground truth\n",
    "    predictions_data = {\n",
    "        'train_predictions': train_preds.tolist() if isinstance(train_preds, np.ndarray) else train_preds,\n",
    "        'train_ground_truth': train_gt_labels.tolist() if isinstance(train_gt_labels, np.ndarray) else train_gt_labels,\n",
    "        'test_predictions': test_preds.tolist() if isinstance(test_preds, np.ndarray) else test_preds,\n",
    "        'test_ground_truth': test_gt_labels.tolist() if isinstance(test_gt_labels, np.ndarray) else test_gt_labels\n",
    "    }\n",
    "    pred_path = os.path.join(save_folder, f\"predictions_{timestamp}.pkl\")\n",
    "    with open(pred_path, 'wb') as f:\n",
    "        pickle.dump(predictions_data, f)\n",
    "    \n",
    "    # Save all metrics\n",
    "    metrics_path = os.path.join(save_folder, f\"metrics_{timestamp}.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    # Save the configuration\n",
    "    config_path = os.path.join(save_folder, f\"config_{timestamp}.json\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    print(f\"Model, predictions, ground truth, and metrics saved in {save_folder}\")\n",
    "\n",
    "\n",
    "def train_and_eval_final_model(best_config, best_threshold, df):\n",
    "    print('\\nBEGIN TRAIN AND EVALUATION FINAL MODEL\\n')\n",
    "    feature_columns = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        \"ZHEARTRATE\",\n",
    "    ]\n",
    "\n",
    "    # Hyper parameter loading\n",
    "    device = best_config['device'] \n",
    "    window_size = best_config['window_size']\n",
    "    input_size = len(feature_columns)\n",
    "    batch_size = best_config['batch_size']\n",
    "    hdc_dimension = best_config['hdc_dimension']\n",
    "    ngrams = best_config['ngrams']\n",
    "    learning_rate = best_config['learning_rate']\n",
    "    epochs = best_config['epochs']\n",
    "    patience = best_config['patience']\n",
    "    runtime_log_fld = best_config['runtime_log_fld']\n",
    "    overlap_ratio = best_config['overlap_ratio']\n",
    "    \n",
    "    train_user = list(set(ALL_USERS)- set(TEST_USERS))\n",
    "    test_user = TEST_USERS\n",
    "        \n",
    "    train_data = df[df['user_id'].isin(train_user)]\n",
    "    test_data = df[df['user_id'].isin(test_user)]\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    scaler = StandardScaler()\n",
    "    train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "    test_data[columns_to_standardize] = scaler.transform(test_data[columns_to_standardize])\n",
    "\n",
    "    print(\"Preparing sequences...\")\n",
    "    X_train, y_train, train_user_ids = prepare_sequences_balanced(train_data, window_size, overlap_ratio)\n",
    "    X_test, y_test, test_user_ids = prepare_sequences_balanced(test_data, window_size, overlap_ratio)\n",
    "\n",
    "    print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "    print(f\"Users in test:{set(test_data['user_id'])}\")\n",
    "    print(f\"Number of windows for training:{len(X_train)}\")\n",
    "    print(f\"Number of windows for testing:{len(X_test)}\")\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = HdcModel(input_size, hdc_dimension, ngrams, device=device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 02. Train model (set patience to ensure that the model is trained for the best epoch)\n",
    "    model, training_history, _ = train_model(\n",
    "        model=model, train_loader=train_loader, valid_loader=None, \n",
    "        criterion=criterion, lr=learning_rate, device=device, epochs=epochs\n",
    "    )\n",
    "\n",
    "    # 03. Inference\n",
    "    train_preds, train_gt_labels = inference_dataset(model, train_loader, device)\n",
    "    test_preds, test_gt_labels = inference_dataset(model, test_loader, device)\n",
    "\n",
    "    # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "    train_roc_auc, train_pr_auc, train_accuracy, train_sober_acc, train_drunk_acc, train_f1, train_threshold = performance_calculation(train_preds, train_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Training ROC-AUC: {train_roc_auc:.4f}, PR-AUC: {train_pr_auc:.4f}, Accuracy: {train_accuracy:.4f}, Sober Accuracy: {train_sober_acc:.4f}, Drunk Accuracy: {train_drunk_acc:.4f}, F1: {train_f1:.4f}, Threshold: {train_threshold:.4f}\")\n",
    "    test_roc_auc, test_pr_auc, test_accuracy, test_sober_acc, test_drunk_acc, test_f1, test_threshold = performance_calculation(test_preds, test_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Test ROC-AUC: {test_roc_auc:.4f}, PR-AUC: {test_pr_auc:.4f}, Accuracy: {test_accuracy:.4f}, Sober Accuracy: {test_sober_acc:.4f}, Drunk Accuracy: {test_drunk_acc:.4f}, F1: {test_f1:.4f}, Threshold: {test_threshold:.4f}\")    \n",
    "\n",
    "    # 05. Save model, predictions, ground truth, metrics and model structure\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'roc_auc': train_roc_auc,\n",
    "            'pr_auc': train_pr_auc,\n",
    "            'accuracy': train_accuracy,\n",
    "            'sober_accuracy': train_sober_acc,\n",
    "            'drunk_accuracy': train_drunk_acc,\n",
    "            'f1': train_f1,\n",
    "            'threshold': train_threshold\n",
    "        },\n",
    "        'test': {\n",
    "            'roc_auc': test_roc_auc,\n",
    "            'pr_auc': test_pr_auc,\n",
    "            'accuracy': test_accuracy,\n",
    "            'sober_accuracy': test_sober_acc,\n",
    "            'drunk_accuracy': test_drunk_acc,\n",
    "            'f1': test_f1,\n",
    "            'threshold': test_threshold\n",
    "        },\n",
    "        'config': best_config\n",
    "    }\n",
    "    \n",
    "    # Call the function to save all results\n",
    "    save_model_and_results(\n",
    "        model=model,\n",
    "        save_folder=runtime_log_fld,\n",
    "        train_preds=train_preds,\n",
    "        train_gt_labels=train_gt_labels,\n",
    "        test_preds=test_preds,\n",
    "        test_gt_labels=test_gt_labels,\n",
    "        metrics=metrics,\n",
    "        config=best_config\n",
    "    )\n",
    "    \n",
    "    # refresh GPU\n",
    "    model.to(\"cpu\")\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    return train_accuracy, test_accuracy, metrics\n",
    "\n",
    "def train_cross_validation(df, all_configs):\n",
    "    print(\"=\"*50 + \"\\nBEGIN CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    best_config = None \n",
    "    best_pr_auc = 0\n",
    "    best_threshold = 0.5 \n",
    "    for config_idx, config in enumerate(all_configs):\n",
    "        print(f\"\\nCONFIG {config_idx}: {config}\\n\")\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "        # Hyper parameter loading\n",
    "        device = config['device'] \n",
    "        window_size = config['window_size']\n",
    "        input_size = len(feature_columns)\n",
    "        batch_size = config['batch_size']\n",
    "        hdc_dimension = config['hdc_dimension']\n",
    "        ngrams = config['ngrams']\n",
    "        learning_rate = config['learning_rate']\n",
    "        epochs = config['epochs']\n",
    "        overlap_ratio = config['overlap_ratio']\n",
    "        patience = config['patience']\n",
    "\n",
    "        # variables for temperary storing\n",
    "        val_all_preds = []\n",
    "        val_all_gt_labels = []\n",
    "        val_trained_epoch = []\n",
    "\n",
    "        for fold, (train_user, val_user) in enumerate(zip(TRAIN_USERS, VALID_USERS)):\n",
    "\n",
    "            # 01. Prepare data and define model\n",
    "            print(\"-\" * 100)\n",
    "            print('FOLD:', fold+1)\n",
    "            print('TRAIN:', train_user)\n",
    "            print('VAL:', val_user)\n",
    "            \n",
    "            train_data = df[df['user_id'].isin(train_user)].copy()\n",
    "            val_data = df[df['user_id'].isin(val_user)].copy()\n",
    "\n",
    "            # columns will be normalized\n",
    "            columns_to_standardize = [\n",
    "                \"ZVALUEX_acc\",\n",
    "                \"ZVALUEY_acc\",\n",
    "                \"ZVALUEZ_acc\",\n",
    "                \"ZVALUEX_gyro\",\n",
    "                \"ZVALUEY_gyro\",\n",
    "                \"ZVALUEZ_gyro\",\n",
    "                #'ZHEARTRATE'\n",
    "            ]\n",
    "\n",
    "            # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "            scaler = StandardScaler()\n",
    "            train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "            val_data[columns_to_standardize] = scaler.transform(val_data[columns_to_standardize])\n",
    "\n",
    "            print(\"Preparing sequences...\")\n",
    "            X_train, y_train, train_user_ids = prepare_sequences_balanced(train_data, window_size, overlap_ratio)\n",
    "            X_val, y_val, val_user_ids = prepare_sequences_balanced(val_data, window_size, overlap_ratio)\n",
    "\n",
    "            print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "            print(f\"Users in test:{set(val_data['user_id'])}\")\n",
    "            print(f\"Number of windows for training:{len(X_train)}\")\n",
    "            print(f\"Number of windows for testing:{len(X_val)}\")\n",
    "\n",
    "            train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "            val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            model = HdcModel(input_size, hdc_dimension, ngrams, device=device)\n",
    "\n",
    "            criterion = nn.BCELoss()\n",
    "            #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            # 02. Train model \n",
    "            model, training_history, train_best_epoch = train_model(\n",
    "                model, train_loader, val_loader, criterion, lr=learning_rate, device=device, \n",
    "                epochs=epochs, patience=patience\n",
    "            )\n",
    "\n",
    "            # 03. Inference\n",
    "            val_preds, val_gt_labels = inference_dataset(model, val_loader, device)\n",
    "            val_all_preds.append(val_preds)\n",
    "            val_all_gt_labels.append(val_gt_labels)\n",
    "            val_trained_epoch.append(train_best_epoch)\n",
    "\n",
    "            # refresh GPU\n",
    "            model.to(\"cpu\")\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "        # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "        val_all_preds = np.concatenate(val_all_preds)\n",
    "        val_all_gt_labels = np.concatenate(val_all_gt_labels)\n",
    "        val_roc_auc, val_pr_auc, val_accuracy, val_sober_acc, val_drunk_acc, val_f1, val_threshold = performance_calculation(val_preds, val_gt_labels)\n",
    "        print(f\"Validation ROC-AUC: {val_roc_auc:.4f}, PR-AUC: {val_pr_auc:.4f}, Accuracy: {val_accuracy:.4f}, Sober Accuracy: {val_sober_acc:.4f}, Drunk Accuracy: {val_drunk_acc:.4f}, F1: {val_f1:.4f}, Threshold: {val_threshold:.4f}\")\n",
    "        \n",
    "        # 05. set up best config\n",
    "        if val_pr_auc > best_pr_auc:\n",
    "            best_pr_auc = val_pr_auc\n",
    "            best_config = config\n",
    "            best_threshold = val_threshold\n",
    "            best_config_epoch = np.ceil(np.mean(val_trained_epoch)) + 1\n",
    "            print(f\"Updated best config: {best_config}, PR-AUC: {best_pr_auc:.4f}, Threshold: {best_threshold:.4f}, Epoch: {best_config_epoch:.2f}\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    best_config['epochs'] = int(best_config_epoch)\n",
    "    best_config['patience'] = int(best_config_epoch)\n",
    "    print(f'Final best config: {best_config}, Final best pr_auc: {best_pr_auc}, Final best threshold: {best_threshold}, Final best epoch: {best_config_epoch}')\n",
    "    print(\"=\"*50 + \"\\nEND CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    return best_config, best_pr_auc, best_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_file_path):\n",
    "    # Configure logging\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Remove existing handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Add file handler\n",
    "    file_handler = logging.FileHandler(log_file_path)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Create a custom print function\n",
    "    original_print = print\n",
    "    \n",
    "    def custom_print(*args, **kwargs):\n",
    "        # Call original print\n",
    "        # original_print(*args, **kwargs)\n",
    "        # Log the printed content\n",
    "        message = \" \".join(str(arg) for arg in args)\n",
    "        logger.info(f\"PRINT: {message}\")\n",
    "    \n",
    "    # Replace built-in print\n",
    "    import builtins\n",
    "    builtins.print = custom_print\n",
    "    \n",
    "    logger.info(f\"Logging initialized to {os.path.abspath(log_file_path)}\")\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime():\n",
    "    # 1.set up logging\n",
    "    runtime_log_fld = f\"results/{MODEL_NAME}/{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    if os.path.exists(runtime_log_fld) == False:\n",
    "        os.makedirs(runtime_log_fld)\n",
    "    logger = setup_logging(f\"{runtime_log_fld}/training.log\")\n",
    "    \n",
    "    # 2.set up configurations\n",
    "    base_configs = BASE_CONFIGS\n",
    "    base_configs['runtime_log_fld'] = runtime_log_fld   \n",
    "    all_configs = generate_configs(base_configs)\n",
    "    print(f\"Total configurations: {len(all_configs)}\")\n",
    "\n",
    "    # 3.Load the raw data\n",
    "    df = load_data()\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    # scaler = StandardScaler()\n",
    "    # df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "    # 4. Train and evaluate all configurations\n",
    "    # get the best config of current model \n",
    "    # get the best threshold of drunk or sober based on all fold validation data when using best config\n",
    "    best_config, best_pr_auc, best_threshold = train_cross_validation(df, all_configs)\n",
    "\n",
    "    # 5.Train and evaluate the final model with the best configuration\n",
    "    # train the final model on all data in cross validation and evaluate on test data\n",
    "    # calculate the performance and save the model, metrics and best config \n",
    "    train_and_eval_final_model(best_config, best_threshold, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:04<00:00,  9.33it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 19.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m runtime()\n",
      "Cell \u001b[0;32mIn[11], line 34\u001b[0m, in \u001b[0;36mruntime\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m columns_to_standardize \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZVALUEX_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZVALUEY_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#'ZHEARTRATE'\u001b[39;00m\n\u001b[1;32m     25\u001b[0m ]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# scaler = StandardScaler()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# get the best config of current model \u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# get the best threshold of drunk or sober based on all fold validation data when using best config\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m best_config, best_pr_auc, best_threshold \u001b[38;5;241m=\u001b[39m train_cross_validation(df, all_configs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 5.Train and evaluate the final model with the best configuration\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# train the final model on all data in cross validation and evaluate on test data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# calculate the performance and save the model, metrics and best config \u001b[39;00m\n\u001b[1;32m     39\u001b[0m train_and_eval_final_model(best_config, best_threshold, df)\n",
      "Cell \u001b[0;32mIn[9], line 255\u001b[0m, in \u001b[0;36mtrain_cross_validation\u001b[0;34m(df, all_configs)\u001b[0m\n\u001b[1;32m    251\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# 02. Train model \u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m model, training_history, train_best_epoch \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m    256\u001b[0m     model, train_loader, val_loader, criterion, lr\u001b[38;5;241m=\u001b[39mlearning_rate, device\u001b[38;5;241m=\u001b[39mdevice, \n\u001b[1;32m    257\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs, patience\u001b[38;5;241m=\u001b[39mpatience\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# 03. Inference\u001b[39;00m\n\u001b[1;32m    261\u001b[0m val_preds, val_gt_labels \u001b[38;5;241m=\u001b[39m inference_dataset(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[8], line 281\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, criterion, lr, device, epochs, patience)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    279\u001b[0m     batch_X, batch_y \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39mto(device), batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 281\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(batch_X, batch_y, lr)\n\u001b[1;32m    282\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m    283\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[8], line 93\u001b[0m, in \u001b[0;36mHdcModel.add\u001b[0;34m(self, x, y, lr)\u001b[0m\n\u001b[1;32m     90\u001b[0m labels \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hv)):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m#This operations can't be done in batches\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroid\u001b[38;5;241m.\u001b[39madd_adjust(\n\u001b[1;32m     94\u001b[0m             hv[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), labels[i], lr\u001b[38;5;241m=\u001b[39mlr\n\u001b[1;32m     95\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/TFG/wearbac_experiments/torchhd/torchhd/models.py:204\u001b[0m, in \u001b[0;36mCentroid.add_adjust\u001b[0;34m(self, input, target, lr)\u001b[0m\n\u001b[1;32m    202\u001b[0m logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    203\u001b[0m predx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(logit, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 204\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([predx\u001b[38;5;241m.\u001b[39mindices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    205\u001b[0m is_wrong \u001b[38;5;241m=\u001b[39m target \u001b[38;5;241m!=\u001b[39m pred\n\u001b[1;32m    207\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mabs\u001b[39m(predx[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mabs\u001b[39m(predx[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/Desktop/TFG/wearbac_experiments/torchhd/torchhd/tensors/base.py:459\u001b[0m, in \u001b[0;36mVSATensor.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;66;03m# Return the scalar value inside the zero-dimensional tensor\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;66;03m# Return a new VSATensor wrapping the tensor result\u001b[39;00m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "files = glob(\"results/HDC_balanced/20250409_114215/predictions_*.pkl\")\n",
    "assert len(files) > 0, \"No prediction files found!\"\n",
    "file_path = files[0]\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "\n",
    "# Get raw test predictions and labels\n",
    "test_probs = np.array(predictions[\"test_predictions\"])\n",
    "test_labels = np.array(predictions[\"test_ground_truth\"])\n",
    "\n",
    "# Use same threshold as during training\n",
    "threshold = 0.07  # or dynamically extract it from your saved metrics\n",
    "\n",
    "# Convert to binary predictions\n",
    "test_binary_preds = (test_probs >= threshold).astype(int)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_binary_preds)\n",
    "\n",
    "# Print it\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Predicted Sober\", \"Predicted Drunk\"],\n",
    "            yticklabels=[\"Actual Sober\", \"Actual Drunk\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
