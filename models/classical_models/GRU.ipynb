{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# biLSTM model training notebook \n",
    "\n",
    "Steps:\n",
    "- load raw data \n",
    "- generate configs (hyper parameter)\n",
    "- do cross validation to find the best configs (hyper parameters)\n",
    "- train the model with the best hyperparameters in entire data from cross validation step \n",
    "- evaluate the model with test data (not included in cross validation train/val set)\n",
    "- save the model and result\n",
    "\n",
    "Note:\n",
    "in this notebook, the final performance of the model is evaluated with test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:03<00:00,  9.61it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 19.51it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.12it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.31it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.69it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.90it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.14it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.52it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.77it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.39it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 19.08it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.14it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.36it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.65it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.84it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.14it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.35it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.67it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 19.00it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.09it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.23it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.67it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  8.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 17.16it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.03it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.24it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.73it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  8.88it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.80it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 14.89it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.28it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.59it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.32it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.73it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 14.83it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.17it/s]\n",
      "100%|██████████| 33/33 [00:03<00:00,  9.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.37it/s]\n",
      "100%|██████████| 43/43 [00:04<00:00,  9.79it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 20.32it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME='GRU_DATA_AUGMENTATION'\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "import builtins\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Literal\n",
    "import json \n",
    "import pickle\n",
    "# import torchmetrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "from glob import glob\n",
    "import polars as pl \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "RAW_COLUMNS = ['user_id', 'ZTIME', 'ZVALUEX_acc', 'ZVALUEY_acc', \n",
    "               'ZVALUEZ_acc', 'ZVALUEX_gyro', 'ZVALUEY_gyro', 'ZVALUEZ_gyro', 'ZHEARTRATE', 'ZAVERAGEHEARTRATE', \n",
    "              'tac (ug/L)', 'tac_flg', 'session_id']\n",
    "\n",
    "TAC_THRESHOLD = 35\n",
    "TAC_LEVEL_0 = 0\n",
    "TAC_LEVEL_1 = 1\n",
    "\n",
    "ALL_USERS = [ 6,  9, 10, 11, 14, 15, 16, 24, 25, 26, 28, 31]\n",
    "\n",
    "TRAIN_USERS = [[9, 10, 14, 15, 24, 28, 31],\n",
    "[10, 11, 6, 31],\n",
    "[6, 9, 11, 14, 15, 24, 28]]\n",
    "\n",
    "\n",
    "VALID_USERS = [[11, 6],\n",
    "[9, 14, 15, 24, 28],\n",
    "[10, 31]]\n",
    "\n",
    "TEST_USERS = [16,25,26]\n",
    "\n",
    "# base config \n",
    "BASE_CONFIGS = {\n",
    "    \"device\": \"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    \"window_size\": [40*20],\n",
    "    \"hidden_size\": [64,128],\n",
    "    \"num_layers\": [1,2],\n",
    "    \"batch_size\": [128],\n",
    "    \"dropout\": [0.1,0.5],\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 100,\n",
    "    \"patience\": 5, # early stopping\n",
    "    \"overlap_ratio\": 0.5,\n",
    "}\n",
    "def add_noise(seq, level=0.01):\n",
    "    return seq + np.random.normal(0, level, seq.shape)\n",
    "\n",
    "def augment_class(seqs, labels, users, n_aug=1):\n",
    "    new_seqs, new_labels, new_users = [], [], []\n",
    "    for i in range(len(seqs)):\n",
    "        for _ in range(n_aug):\n",
    "            aug_seq = add_noise(seqs[i])\n",
    "            new_seqs.append(aug_seq)\n",
    "            new_labels.append(labels[i])\n",
    "            new_users.append(users[i])\n",
    "    return np.concatenate([seqs, np.stack(new_seqs)]), np.concatenate([labels, new_labels]), np.concatenate([users, new_users])\n",
    "\n",
    "def load_data(preprocess_fld='../../Preprocessed_all'):\n",
    "    file_paths = sorted(glob(preprocess_fld + '/after_preprocess_group*.csv'))\n",
    "    df_final = [pl.read_csv(file_path, columns=RAW_COLUMNS) for file_path in file_paths]\n",
    "    # get the same columns from all the dataframes\n",
    "    columns = df_final[-1].columns\n",
    "    # Optionally, you can concatenate the DataFrames into a single DataFrame\n",
    "    df_final = pl.concat([data_df[columns] for data_df in df_final])\n",
    "    # filter user \n",
    "    df_final  = df_final.filter(df_final['user_id'].is_in(ALL_USERS))\n",
    "    # Create new session_id such that it is unique for all users\n",
    "    df_final = (\n",
    "        df_final.with_columns([\n",
    "            pl.concat_str([\n",
    "                pl.col('user_id').cast(pl.Utf8),\n",
    "                pl.lit('_'),\n",
    "                pl.col('session_id')\n",
    "            ]).alias('combined_key')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col('combined_key').rank(method='dense').cast(pl.Int32).alias('session_id')\n",
    "        ])\n",
    "    )\n",
    "    df_final = df_final.drop('combined_key')\n",
    "    df_final = df_final.with_columns(\n",
    "        tac_flg=(df_final['tac (ug/L)'] < TAC_THRESHOLD).cast(float)\n",
    "\n",
    "    )\n",
    "    return df_final.to_pandas()\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, features, labels, window_size=10):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]),\n",
    "            torch.FloatTensor([self.labels[idx]]),\n",
    "        )\n",
    "\n",
    "def prepare_sequences_undersampled(df, window_size=10, overlap_ratio=0.1, feature_columns=None):\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\", \"ZVALUEY_acc\", \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\", \"ZVALUEY_gyro\", \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\"\n",
    "        ]\n",
    "\n",
    "    session_user_map = pd.Series(df[\"user_id\"].values, index=df[\"session_id\"]).astype(int).to_dict()\n",
    "    features = df[feature_columns].values\n",
    "    labels = df[\"tac_flg\"].values\n",
    "    session_ids = df[\"session_id\"].values\n",
    "    unique_sessions = np.unique(session_ids)\n",
    "\n",
    "    sequences, sequence_labels, sequence_user_ids = [], [], []\n",
    "\n",
    "    for session_id in tqdm(unique_sessions):\n",
    "        session_mask = session_ids == session_id\n",
    "        session_indices = np.where(session_mask)[0]\n",
    "        if len(session_indices) >= window_size:\n",
    "            for start_idx in range(0, len(session_indices) - window_size + 1, int(window_size * overlap_ratio)):\n",
    "                window_indices = session_indices[start_idx: start_idx + window_size]\n",
    "                if len(window_indices) < window_size:\n",
    "                    continue\n",
    "                sequence = features[window_indices]\n",
    "                label = int(stats.mode(labels[window_indices].astype(int), keepdims=False).mode)\n",
    "                sequences.append(sequence)\n",
    "                sequence_labels.append(label)\n",
    "                sequence_user_ids.append(session_user_map[session_id])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequence_labels = np.array(sequence_labels)\n",
    "    sequence_user_ids = np.array(sequence_user_ids)\n",
    "\n",
    "    # Split by class\n",
    "    sober_mask = sequence_labels == 1\n",
    "    drunk_mask = sequence_labels == 0\n",
    "\n",
    "    sober_seqs, sober_labels, sober_users = sequences[sober_mask], sequence_labels[sober_mask], sequence_user_ids[sober_mask]\n",
    "    drunk_seqs, drunk_labels, drunk_users = sequences[drunk_mask], sequence_labels[drunk_mask], sequence_user_ids[drunk_mask]\n",
    "\n",
    "    # Augment minority class (drunk)\n",
    "    drunk_seqs, drunk_labels, drunk_users = augment_class(drunk_seqs, drunk_labels, drunk_users, n_aug=1)\n",
    "\n",
    "    # Undersample majority class\n",
    "    n_samples = min(len(sober_seqs), len(drunk_seqs))\n",
    "    indices = np.random.choice(len(sober_seqs), size=n_samples, replace=False)\n",
    "    sober_seqs, sober_labels, sober_users = sober_seqs[indices], sober_labels[indices], sober_users[indices]\n",
    "\n",
    "    # Merge and shuffle\n",
    "    all_seqs = np.concatenate([sober_seqs, drunk_seqs])\n",
    "    all_labels = np.concatenate([sober_labels, drunk_labels])\n",
    "    all_users = np.concatenate([sober_users, drunk_users])\n",
    "    idx = np.arange(len(all_labels))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    return all_seqs[idx], all_labels[idx], all_users[idx]\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=64,\n",
    "        num_layers=2,\n",
    "        dropout=0.2,\n",
    "        bidirectional=True,\n",
    "        pooling=\"attention\",\n",
    "    ):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.pooling = pooling\n",
    "\n",
    "        # bidirectionalの場合、出力の次元数が2倍になる\n",
    "        self.direction_factor = 2 if bidirectional else 1\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        # Attention層（pooling='attention'の場合に使用）\n",
    "        if pooling == \"attention\":\n",
    "            self.attention = nn.Sequential(\n",
    "                nn.Linear(hidden_size * self.direction_factor, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_size, 1),\n",
    "            )\n",
    "\n",
    "        # 全結合層の入力サイズを調整\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * self.direction_factor, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def attention_pooling(self, gru_out):\n",
    "        attention_weights = self.attention(gru_out)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        attended_out = torch.sum(attention_weights * gru_out, dim=1)\n",
    "        return attended_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        pooled_output = gru_out[:, -1, :]\n",
    "\n",
    "        return self.fc(pooled_output)\n",
    "\n",
    "\n",
    "def prepare_sequences_fast(df, window_size=10, overlap_ratio=0.1, feature_columns=None):\n",
    "    session_user_map = pd.Series(df[\"user_id\"].values, index=df[\"session_id\"]).astype(int).to_dict()\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "    print(f\"Starting sequence preparation...\")\n",
    "\n",
    "    # 特徴量とラベルを事前にNumPy配列に変換\n",
    "    features = df[feature_columns].values\n",
    "    labels = df[\"tac_flg\"].values\n",
    "    session_ids = df[\"session_id\"].values\n",
    "\n",
    "    # セッションのユニークなIDと各セッションのインデックスを取得\n",
    "    unique_sessions = np.unique(session_ids)\n",
    "    print(f\"Processing {len(unique_sessions)} sessions...\")\n",
    "\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    sequence_user_ids = []\n",
    "\n",
    "    for session_id in tqdm(unique_sessions):\n",
    "        session_mask = session_ids == session_id\n",
    "        session_indices = np.where(session_mask)[0]\n",
    "\n",
    "        if len(session_indices) >= window_size:\n",
    "            for start_idx in range(\n",
    "                0, len(session_indices) - window_size + 1, np.ceil(window_size*overlap_ratio).astype(int)\n",
    "            ):\n",
    "                window_indices = session_indices[start_idx : start_idx + window_size]\n",
    "                if len(window_indices) < window_size:\n",
    "                    continue\n",
    "\n",
    "                sequence = features[window_indices]\n",
    "                # get the mode label in the current window\n",
    "                label = stats.mode(labels[window_indices].astype(int))[0]\n",
    "\n",
    "                sequences.append(sequence)\n",
    "                sequence_labels.append(label)\n",
    "                sequence_user_ids.append(session_user_map[session_id])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "    print(f\"Created {len(sequences)} sequences\")\n",
    "    print(f\"Sequences shape: {sequences.shape}\")\n",
    "\n",
    "    return sequences, sequence_labels, sequence_user_ids\n",
    "\n",
    "\n",
    "def validate_model(model, valid_loader, criterion, device):\n",
    "    \"\"\"検証データでのモデル評価\"\"\"\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(outputs.cpu().numpy())\n",
    "            val_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    val_prauc = average_precision_score(val_labels, val_preds)\n",
    "    val_rocauc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    return {\n",
    "        \"loss\": val_loss / len(valid_loader),\n",
    "        \"pr_auc\": val_prauc,\n",
    "        \"roc_auc\": val_rocauc,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=100,\n",
    "    patience=5,\n",
    "):\n",
    "    best_val_prauc = 0\n",
    "    patience_counter = 0\n",
    "    best_train_epoch = 0\n",
    "    best_model_state = None\n",
    "    training_history = []\n",
    "\n",
    "    print(\n",
    "        \"Epoch | Train Loss |  Val Loss  |  Val PR-AUC  |  Val ROC-AUC  |  Epoch Time (s)\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        if valid_loader is None:\n",
    "            epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"time\": epoch_time}\n",
    "            training_history.append(epoch_results)\n",
    "            print(f\"{epoch+1:5d} | {train_loss:.6f} | ------ | ------ | {epoch_time:.2f}\")\n",
    "            continue\n",
    "    \n",
    "        val_metrics = validate_model(model, valid_loader, criterion, device)\n",
    "        epoch_results = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_metrics[\"loss\"], \n",
    "                         \"val_pr_auc\": val_metrics[\"pr_auc\"], \"val_roc_auc\": val_metrics[\"roc_auc\"], \"time\": epoch_time}\n",
    "        training_history.append(epoch_results)\n",
    "\n",
    "        print(\n",
    "            f\"{epoch+1:5d} | {train_loss:.6f} | {val_metrics['loss']:.6f} | \"\n",
    "            f\"{val_metrics['pr_auc']:.4f} | {val_metrics['roc_auc']:.4f} | \"\n",
    "            f\"{epoch_time:.2f}\"\n",
    "        )\n",
    "        \n",
    "        if val_metrics[\"pr_auc\"] >= best_val_prauc:\n",
    "            best_val_prauc = val_metrics[\"pr_auc\"]\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "            best_train_epoch = epoch\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after epoch {epoch+1}\")\n",
    "            print(f\"Best validation PR-AUC: {best_val_prauc:.4f}\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None: \n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model, training_history, best_train_epoch\n",
    "\n",
    "\n",
    "def inference_dataset(model, data_loader, device, pred_threshold=None):\n",
    "    \"\"\"evaluation model after a fold training\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            labels.extend(batch_y.numpy())\n",
    "\n",
    "    pred_prob = np.array(predictions)\n",
    "    gt_labels = np.array(labels)\n",
    "    return pred_prob, gt_labels\n",
    "\n",
    "\n",
    "def performance_calculation(pred_prob, gt_label, threshold=None):\n",
    "    '''\n",
    "    Calculate the performance of the model\n",
    "    Args:\n",
    "    pred_prob: list, predicted probability\n",
    "    gt_label: list, ground truth label\n",
    "    threshold: float, threshold for binary classification (None if we are evaluating on train data)\n",
    "    '''\n",
    "    if threshold is None:\n",
    "        # Find the optimal threshold by maximizing F1 score\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)  # Test 99 threshold values\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5  # Default if no better threshold is found\n",
    "        \n",
    "        for t in thresholds:\n",
    "            temp_pred = (pred_prob >= t).astype(int)\n",
    "            temp_f1 = f1_score(gt_label, temp_pred)\n",
    "            \n",
    "            if temp_f1 > best_f1:\n",
    "                best_f1 = temp_f1\n",
    "                best_threshold = t\n",
    "        \n",
    "        threshold = best_threshold\n",
    "        \n",
    "    pred_label = (pred_prob >= threshold).astype(int)\n",
    "    roc_auc = roc_auc_score(gt_label, pred_prob)\n",
    "    pr_auc = average_precision_score(gt_label, pred_prob)\n",
    "    accuracy = accuracy_score(gt_label, pred_label)\n",
    "    sober_acc = accuracy_score(gt_label[gt_label == 0], pred_label[gt_label == 0])\n",
    "    drunk_acc = accuracy_score(gt_label[gt_label == 1], pred_label[gt_label == 1])\n",
    "    f1 = f1_score(gt_label, pred_label)\n",
    "    return roc_auc, pr_auc, accuracy, sober_acc, drunk_acc, f1, threshold\n",
    "\n",
    "\n",
    "def generate_configs(base_config):\n",
    "    \"\"\"\n",
    "    Generate multiple configurations from a base config.\n",
    "    For any list values in the base config, create a separate config for each list item.\n",
    "    \n",
    "    Args:\n",
    "        base_config (dict): Base configuration with potential list values\n",
    "        \n",
    "    Returns:\n",
    "        list: List of individual configurations\n",
    "    \"\"\"\n",
    "    # Find all keys with list values\n",
    "    list_keys = [key for key, value in base_config.items() if isinstance(value, list)]\n",
    "    \n",
    "    if not list_keys:\n",
    "        # If no list values found, return the original config\n",
    "        return [base_config]\n",
    "    \n",
    "    # Start with the first list key\n",
    "    key = list_keys[0]\n",
    "    values = base_config[key]\n",
    "    \n",
    "    # Generate configurations for each value of the first list key\n",
    "    configs = []\n",
    "    for value in values:\n",
    "        # Create a new config with this specific value\n",
    "        new_config = base_config.copy()\n",
    "        new_config[key] = value\n",
    "        \n",
    "        # Recursively handle any remaining list keys\n",
    "        remaining_configs = generate_configs(new_config)\n",
    "        configs.extend(remaining_configs)\n",
    "    \n",
    "    return configs\n",
    "\n",
    "\n",
    "def save_model_and_results(model, save_folder, train_preds, train_gt_labels, test_preds, test_gt_labels, metrics, config):\n",
    "    \"\"\"\n",
    "    Save model, predictions, ground truth, metrics, and model structure to the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        save_folder: Folder path to save results\n",
    "        train_preds: Training predictions\n",
    "        train_gt_labels: Training ground truth labels\n",
    "        test_preds: Test predictions\n",
    "        test_gt_labels: Test ground truth labels\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "        config: Model configuration dictionary\n",
    "    \"\"\"\n",
    "    # Create a timestamp for the save files\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(save_folder, f\"model_{timestamp}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save model architecture as text\n",
    "    model_structure_path = os.path.join(save_folder, f\"model_structure_{timestamp}.txt\")\n",
    "    with open(model_structure_path, 'w') as f:\n",
    "        f.write(str(model))\n",
    "    \n",
    "    # Save predictions and ground truth\n",
    "    predictions_data = {\n",
    "        'train_predictions': train_preds.tolist() if isinstance(train_preds, np.ndarray) else train_preds,\n",
    "        'train_ground_truth': train_gt_labels.tolist() if isinstance(train_gt_labels, np.ndarray) else train_gt_labels,\n",
    "        'test_predictions': test_preds.tolist() if isinstance(test_preds, np.ndarray) else test_preds,\n",
    "        'test_ground_truth': test_gt_labels.tolist() if isinstance(test_gt_labels, np.ndarray) else test_gt_labels\n",
    "    }\n",
    "    pred_path = os.path.join(save_folder, f\"predictions_{timestamp}.pkl\")\n",
    "    with open(pred_path, 'wb') as f:\n",
    "        pickle.dump(predictions_data, f)\n",
    "    \n",
    "    # Save all metrics\n",
    "    metrics_path = os.path.join(save_folder, f\"metrics_{timestamp}.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    # Save the configuration\n",
    "    config_path = os.path.join(save_folder, f\"config_{timestamp}.json\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    print(f\"Model, predictions, ground truth, and metrics saved in {save_folder}\")\n",
    "\n",
    "\n",
    "def train_and_eval_final_model(best_config, best_threshold, df):\n",
    "    print('\\nBEGIN TRAIN AND EVALUATION FINAL MODEL\\n')\n",
    "    feature_columns = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        \"ZHEARTRATE\",\n",
    "    ]\n",
    "\n",
    "    # Hyper parameter loading\n",
    "    device = best_config['device'] \n",
    "    window_size = best_config['window_size']\n",
    "    input_size = len(feature_columns)\n",
    "    hidden_size = best_config['hidden_size']\n",
    "    num_layers = best_config['num_layers']\n",
    "    batch_size = best_config['batch_size']\n",
    "    dropout = best_config['dropout']\n",
    "    learning_rate = best_config['learning_rate']\n",
    "    epochs = best_config['epochs']\n",
    "    patience = best_config['patience']\n",
    "    runtime_log_fld = best_config['runtime_log_fld']\n",
    "    overlap_ratio = best_config['overlap_ratio']\n",
    "    \n",
    "    train_user = list(set(ALL_USERS)- set(TEST_USERS))\n",
    "    test_user = TEST_USERS\n",
    "        \n",
    "    train_data = df[df['user_id'].isin(train_user)]\n",
    "    test_data = df[df['user_id'].isin(test_user)]\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    scaler = StandardScaler()\n",
    "    train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "    test_data[columns_to_standardize] = scaler.transform(test_data[columns_to_standardize])\n",
    "\n",
    "    print(\"Preparing sequences...\")\n",
    "    X_train, y_train, train_user_ids = prepare_sequences_undersampled(train_data, window_size, overlap_ratio)\n",
    "    X_test, y_test, test_user_ids = prepare_sequences_fast(test_data, window_size, overlap_ratio)\n",
    "\n",
    "    print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "    print(f\"Users in test:{set(test_data['user_id'])}\")\n",
    "    print(f\"Number of windows for training:{len(X_train)}\")\n",
    "    print(f\"Number of windows for testing:{len(X_test)}\")\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = GRUClassifier(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        bidirectional=False,\n",
    "        pooling=\"attention\", \n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 02. Train model (set patience to ensure that the model is trained for the best epoch)\n",
    "    model, training_history, _ = train_model(\n",
    "        model=model, train_loader=train_loader, valid_loader=None, \n",
    "        criterion=criterion, optimizer=optimizer, device=device, \n",
    "        epochs=epochs, patience=patience\n",
    "    )\n",
    "\n",
    "    # 03. Inference\n",
    "    train_preds, train_gt_labels = inference_dataset(model, train_loader, device)\n",
    "    test_preds, test_gt_labels = inference_dataset(model, test_loader, device)\n",
    "\n",
    "    # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "    train_roc_auc, train_pr_auc, train_accuracy, train_sober_acc, train_drunk_acc, train_f1, train_threshold = performance_calculation(train_preds, train_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Training ROC-AUC: {train_roc_auc:.4f}, PR-AUC: {train_pr_auc:.4f}, Accuracy: {train_accuracy:.4f}, Sober Accuracy: {train_sober_acc:.4f}, Drunk Accuracy: {train_drunk_acc:.4f}, F1: {train_f1:.4f}, Threshold: {train_threshold:.4f}\")\n",
    "    test_roc_auc, test_pr_auc, test_accuracy, test_sober_acc, test_drunk_acc, test_f1, test_threshold = performance_calculation(test_preds, test_gt_labels, threshold=best_threshold)\n",
    "    print(f\"Test ROC-AUC: {test_roc_auc:.4f}, PR-AUC: {test_pr_auc:.4f}, Accuracy: {test_accuracy:.4f}, Sober Accuracy: {test_sober_acc:.4f}, Drunk Accuracy: {test_drunk_acc:.4f}, F1: {test_f1:.4f}, Threshold: {test_threshold:.4f}\")    \n",
    "\n",
    "    # 05. Save model, predictions, ground truth, metrics and model structure\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'roc_auc': train_roc_auc,\n",
    "            'pr_auc': train_pr_auc,\n",
    "            'accuracy': train_accuracy,\n",
    "            'sober_accuracy': train_sober_acc,\n",
    "            'drunk_accuracy': train_drunk_acc,\n",
    "            'f1': train_f1,\n",
    "            'threshold': train_threshold\n",
    "        },\n",
    "        'test': {\n",
    "            'roc_auc': test_roc_auc,\n",
    "            'pr_auc': test_pr_auc,\n",
    "            'accuracy': test_accuracy,\n",
    "            'sober_accuracy': test_sober_acc,\n",
    "            'drunk_accuracy': test_drunk_acc,\n",
    "            'f1': test_f1,\n",
    "            'threshold': test_threshold\n",
    "        },\n",
    "        'config': best_config\n",
    "    }\n",
    "    \n",
    "    # Call the function to save all results\n",
    "    save_model_and_results(\n",
    "        model=model,\n",
    "        save_folder=runtime_log_fld,\n",
    "        train_preds=train_preds,\n",
    "        train_gt_labels=train_gt_labels,\n",
    "        test_preds=test_preds,\n",
    "        test_gt_labels=test_gt_labels,\n",
    "        metrics=metrics,\n",
    "        config=best_config\n",
    "    )\n",
    "    \n",
    "    # refresh GPU\n",
    "    model.to(\"cpu\")\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    return train_accuracy, test_accuracy, metrics\n",
    "\n",
    "def train_cross_validation(df, all_configs):\n",
    "    print(\"=\"*50 + \"\\nBEGIN CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    best_config = None \n",
    "    best_pr_auc = 0\n",
    "    best_threshold = 0.5 \n",
    "    for config_idx, config in enumerate(all_configs):\n",
    "        print(f\"\\nCONFIG {config_idx}: {config}\\n\")\n",
    "        feature_columns = [\n",
    "            \"ZVALUEX_acc\",\n",
    "            \"ZVALUEY_acc\",\n",
    "            \"ZVALUEZ_acc\",\n",
    "            \"ZVALUEX_gyro\",\n",
    "            \"ZVALUEY_gyro\",\n",
    "            \"ZVALUEZ_gyro\",\n",
    "            \"ZHEARTRATE\",\n",
    "        ]\n",
    "\n",
    "        # Hyper parameter loading\n",
    "        device = config['device'] \n",
    "        window_size = config['window_size']\n",
    "        input_size = len(feature_columns)\n",
    "        hidden_size = config['hidden_size']\n",
    "        num_layers = config['num_layers']\n",
    "        batch_size = config['batch_size']\n",
    "        dropout = config['dropout']\n",
    "        learning_rate = config['learning_rate']\n",
    "        epochs = config['epochs']\n",
    "        overlap_ratio = config['overlap_ratio']\n",
    "\n",
    "        # variables for temperary storing\n",
    "        val_all_preds = []\n",
    "        val_all_gt_labels = []\n",
    "        val_trained_epoch = []\n",
    "\n",
    "        for fold, (train_user, val_user) in enumerate(zip(TRAIN_USERS, VALID_USERS)):\n",
    "\n",
    "            # 01. Prepare data and define model\n",
    "            print(\"-\" * 100)\n",
    "            print('FOLD:', fold+1)\n",
    "            print('TRAIN:', train_user)\n",
    "            print('VAL:', val_user)\n",
    "            \n",
    "            train_data = df[df['user_id'].isin(train_user)].copy()\n",
    "            val_data = df[df['user_id'].isin(val_user)].copy()\n",
    "\n",
    "            # columns will be normalized\n",
    "            columns_to_standardize = [\n",
    "                \"ZVALUEX_acc\",\n",
    "                \"ZVALUEY_acc\",\n",
    "                \"ZVALUEZ_acc\",\n",
    "                \"ZVALUEX_gyro\",\n",
    "                \"ZVALUEY_gyro\",\n",
    "                \"ZVALUEZ_gyro\",\n",
    "                #'ZHEARTRATE'\n",
    "            ]\n",
    "\n",
    "            # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "            scaler = StandardScaler()\n",
    "            train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "            val_data[columns_to_standardize] = scaler.transform(val_data[columns_to_standardize])\n",
    "\n",
    "            print(\"Preparing sequences...\")\n",
    "            X_train, y_train, train_user_ids = prepare_sequences_undersampled(train_data, window_size, overlap_ratio)\n",
    "            X_val, y_val, val_user_ids = prepare_sequences_fast(val_data, window_size, overlap_ratio)\n",
    "\n",
    "            print(f\"Users in train:{set(train_data['user_id'])}\")\n",
    "            print(f\"Users in test:{set(val_data['user_id'])}\")\n",
    "            print(f\"Number of windows for training:{len(X_train)}\")\n",
    "            print(f\"Number of windows for testing:{len(X_val)}\")\n",
    "\n",
    "            train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "            val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            model = GRUClassifier(\n",
    "                input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=False,\n",
    "                pooling=\"attention\", \n",
    "            ).to(device)\n",
    "\n",
    "            criterion = nn.BCELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            # 02. Train model \n",
    "            model, training_history, train_best_epoch = train_model(\n",
    "                model, train_loader, val_loader, criterion, optimizer, device, epochs\n",
    "            )\n",
    "\n",
    "            # 03. Inference\n",
    "            val_preds, val_gt_labels = inference_dataset(model, val_loader, device)\n",
    "            val_all_preds.append(val_preds)\n",
    "            val_all_gt_labels.append(val_gt_labels)\n",
    "            val_trained_epoch.append(train_best_epoch)\n",
    "\n",
    "            # refresh GPU\n",
    "            model.to(\"cpu\")\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "        # 04. Calculate performance of current config: ROC, PR-AUC, ACC, F1, Drunk ACC, Sober ACC\n",
    "        val_all_preds = np.concatenate(val_all_preds)\n",
    "        val_all_gt_labels = np.concatenate(val_all_gt_labels)\n",
    "        val_roc_auc, val_pr_auc, val_accuracy, val_sober_acc, val_drunk_acc, val_f1, val_threshold = performance_calculation(val_all_preds, val_all_gt_labels)\n",
    "        print(f\"Validation ROC-AUC: {val_roc_auc:.4f}, PR-AUC: {val_pr_auc:.4f}, Accuracy: {val_accuracy:.4f}, Sober Accuracy: {val_sober_acc:.4f}, Drunk Accuracy: {val_drunk_acc:.4f}, F1: {val_f1:.4f}, Threshold: {val_threshold:.4f}\")\n",
    "        \n",
    "        # 05. set up best config\n",
    "        if val_pr_auc > best_pr_auc:\n",
    "            best_pr_auc = val_pr_auc\n",
    "            best_config = config\n",
    "            best_threshold = val_threshold\n",
    "            best_config_epoch = np.ceil(np.mean(val_trained_epoch)) + 1\n",
    "            print(f\"Updated best config: {best_config}, PR-AUC: {best_pr_auc:.4f}, Threshold: {best_threshold:.4f}, Epoch: {best_config_epoch:.2f}\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    best_config['epochs'] = int(best_config_epoch)\n",
    "    best_config['patience'] = int(best_config_epoch)\n",
    "    print(f'Final best config: {best_config}, Final best pr_auc: {best_pr_auc}, Final best threshold: {best_threshold}, Final best epoch: {best_config_epoch}')\n",
    "    print(\"=\"*50 + \"\\nEND CROSSVALIDATION\\n\" + \"=\"*50)    \n",
    "    return best_config, best_pr_auc, best_threshold\n",
    "\n",
    "\n",
    "def setup_logging(log_file_path):\n",
    "    # Configure logging\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Remove existing handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Add file handler\n",
    "    file_handler = logging.FileHandler(log_file_path)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Create a custom print function\n",
    "    original_print = print\n",
    "    \n",
    "    def custom_print(*args, **kwargs):\n",
    "        # Call original print\n",
    "        # original_print(*args, **kwargs)\n",
    "        # Log the printed content\n",
    "        message = \" \".join(str(arg) for arg in args)\n",
    "        logger.info(f\"PRINT: {message}\")\n",
    "    \n",
    "    # Replace built-in print\n",
    "    import builtins\n",
    "    builtins.print = custom_print\n",
    "    \n",
    "    logger.info(f\"Logging initialized to {os.path.abspath(log_file_path)}\")\n",
    "    return logger\n",
    "def runtime():\n",
    "    # 1.set up logging\n",
    "    runtime_log_fld = f\"results/{MODEL_NAME}/{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    if os.path.exists(runtime_log_fld) == False:\n",
    "        os.makedirs(runtime_log_fld)\n",
    "    logger = setup_logging(f\"{runtime_log_fld}/training.log\")\n",
    "    \n",
    "    # 2.set up configurations\n",
    "    base_configs = BASE_CONFIGS\n",
    "    base_configs['runtime_log_fld'] = runtime_log_fld   \n",
    "    all_configs = generate_configs(base_configs)\n",
    "\n",
    "    # 3.Load the raw data\n",
    "    df = load_data()\n",
    "    # columns will be normalized\n",
    "    columns_to_standardize = [\n",
    "        \"ZVALUEX_acc\",\n",
    "        \"ZVALUEY_acc\",\n",
    "        \"ZVALUEZ_acc\",\n",
    "        \"ZVALUEX_gyro\",\n",
    "        \"ZVALUEY_gyro\",\n",
    "        \"ZVALUEZ_gyro\",\n",
    "        #'ZHEARTRATE'\n",
    "    ]\n",
    "\n",
    "    # # doing normalization (assume that we have the same scaler for all data, faster computing than do it separately)\n",
    "    # scaler = StandardScaler()\n",
    "    # df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "    # 4. Train and evaluate all configurations\n",
    "    # get the best config of current model \n",
    "    # get the best threshold of drunk or sober based on all fold validation data when using best config\n",
    "    best_config, best_pr_auc, best_threshold = train_cross_validation(df, all_configs)\n",
    "\n",
    "    # 5.Train and evaluate the final model with the best configuration\n",
    "    # train the final model on all data in cross validation and evaluate on test data\n",
    "    # calculate the performance and save the model, metrics and best config \n",
    "    train_and_eval_final_model(best_config, best_threshold, df)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    runtime()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
